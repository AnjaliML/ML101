{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dce0d5c-adf1-4aa8-ab98-9694c7834f0f",
   "metadata": {},
   "source": [
    "# MNIST example tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f1b4c9",
   "metadata": {},
   "source": [
    "# import some libraries\n",
    "\n",
    "torch is pytorch. There are also several other functions. </br>\n",
    "matplotlib is for plotting. </br>\n",
    "pickle is a way to read and write data. It output things in .pkl format.  </br>\n",
    "train_test_split is a function to split training and testing data. It comes from the module sklean </br>\n",
    "\n",
    "%matplotlib inline is necessary to plot things in the notebook itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24fa4dd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#limit gpu memory usage\n",
    "# torch.cuda.set_per_process_memory_fraction(0.23, device=0)\n",
    "\n",
    "#change to \"cuda\" to use GPU\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33d15cf",
   "metadata": {},
   "source": [
    "Now, we read the MNIST data. Read more about this dataset here: [https://en.wikipedia.org/wiki/MNIST_database](https://en.wikipedia.org/wiki/MNIST_database)\n",
    "\n",
    "x is the input data and y is the ground truth. By the way, 3Blue1Brown also uses the same dataset. See here: [https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)\n",
    "\n",
    "We will first download the data from: save it in the datasets folder, and then proceeds with the code.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "931641e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded and saved MNIST dataset to datasets/mnist.pkl.gz\n",
      "Extracted MNIST dataset to datasets/mnist.pkl\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Define the URL of the .pkl file\n",
    "url = \"https://github.com/mnielsen/neural-networks-and-deep-learning/raw/master/data/mnist.pkl.gz\"\n",
    "\n",
    "# Define the path where the file will be saved\n",
    "save_path = \"datasets/mnist.pkl.gz\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url)\n",
    "with open(save_path, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "print(f\"Downloaded and saved MNIST dataset to {save_path}\")\n",
    "\n",
    "# Optional: Extract the .pkl file if necessary\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "with gzip.open(save_path, 'rb') as f_in:\n",
    "    with open(save_path[:-3], 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "print(f\"Extracted MNIST dataset to {save_path[:-3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490fa1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data\n",
    "with open(\"datasets/mnist.pkl\",'rb') as f:\n",
    "        dset = pickle.load(f)        \n",
    "\n",
    "#x->input\n",
    "#y->output (ground truth) \n",
    "x,y = dset[\"x\"],dset[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54a599d",
   "metadata": {},
   "source": [
    "Here, we see some characteristics of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95686b30-9651-4c30-bdd6-acc9c93f1818",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=x.shape[0]                   #total number of samples\n",
    "sz=int(np.sqrt(x.shape[1]))    #size of image\n",
    "\n",
    "print(f\"total samples: \\t\\t{N}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77535305",
   "metadata": {},
   "source": [
    "Now, you can plot the images to see the numbers. Always a good idea to visualize the data. Your eyes are the best computer vision tool out there. \n",
    "\n",
    "Task: try plotting more numbers (by changing the argument of range()). See if you recognize these numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61416ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#let's plot some images\n",
    "for img in range(10):\n",
    "    print(y[img])\n",
    "    img = x[img,:].reshape(sz,sz) \n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01368e0d",
   "metadata": {},
   "source": [
    "Now, we split the data into training and testing. Here, we choose 10% of the total data as testing data, i.e., trianing data is 90% of all the images. \n",
    "\n",
    "Task: change this numbers (test_size) and see what happend. You will have to run all the code cells below once you have changed test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa3e85-3e9d-44b1-b20c-cc8afd2db67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data in train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)\n",
    "\n",
    "N_train = x_train.shape[0]\n",
    "\n",
    "print(N_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7384a42a",
   "metadata": {},
   "source": [
    "# define the Neural Network class\n",
    "\n",
    "Here, you create a neural network. Read on the internet what these layers and numbers mean. Please do go online and learn about this. It is the most important part of this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442ef8a1-1168-4d60-8165-46a63c7f340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(input_dim, 20)\n",
    "        self.layer2 = nn.Linear(20, 50)\n",
    "        self.layer3 = nn.Linear(50, output_dim)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5950437f",
   "metadata": {},
   "source": [
    "Now, you will initialize the neural network. Do not worry about \"device\" for now. This code was written in such a way that it could be run on GPU as well. But for now, we will only use CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff435e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the Neural Network\n",
    "model = MLP(sz*sz,10).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bcd1bc",
   "metadata": {},
   "source": [
    "# Choose an optimizer. \n",
    "\n",
    "Read about available optimizers here: [https://pytorch.org/docs/stable/optim.html](https://pytorch.org/docs/stable/optim.html)\n",
    "\n",
    "Read this too: [https://machinelearningknowledge.ai/pytorch-optimizers-complete-guide-for-beginner/](https://machinelearningknowledge.ai/pytorch-optimizers-complete-guide-for-beginner/)\n",
    "\n",
    "Lastly, also here: [https://analyticsindiamag.com/ultimate-guide-to-pytorch-optimizers/](https://analyticsindiamag.com/ultimate-guide-to-pytorch-optimizers/): you must google the names of the optimizer algorithms you find on this page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2823e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#instantiate the optimizer\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "print(optimizer) # prints the different input features of the optimizer. These are the things you can change. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa4306",
   "metadata": {},
   "source": [
    "# define the criterion for the computation of the loss\n",
    "\n",
    "Read about loss criterion here: [https://pytorch.org/docs/stable/nn.html#loss-functions](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "\n",
    "Some details here: [https://neptune.ai/blog/pytorch-loss-functions](https://neptune.ai/blog/pytorch-loss-functions)\n",
    "\n",
    "Basically, this is where you will choose how to estimate the error between the prediction and ground truth while training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4dc56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d7e887",
   "metadata": {},
   "source": [
    "# Training the neural network\n",
    "\n",
    "This is where you train the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56d8013-2c55-4336-bc21-be15eae37740",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 100 #total number of iterations\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    sel = np.random.choice(range(N_train),batch_size,replace=False)\n",
    "    #read data from dataset\n",
    "    x = torch.tensor(x_train[sel],dtype=torch.float32,device=device)\n",
    "    y = torch.tensor(y_train[sel],dtype=torch.long,device=device)\n",
    "\n",
    "    #evaluate the NN\n",
    "    pred = model(x)\n",
    "\n",
    "    #compute the loss, backward and gradient descent\n",
    "    loss = criterion(pred,y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #zero the gradients\n",
    "    optimizer.zero_grad() \n",
    "\n",
    "    #append loss to list\n",
    "    loss_list.append(loss.detach().to('cpu'))\n",
    "        \n",
    "    #print current statistics\n",
    "    print(f\"epoch={epoch}/{epochs}; loss={loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74191e1",
   "metadata": {},
   "source": [
    "Next, we will plot the loss function. See that the loss function decreases sharply but then converges to some constant value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0108ef19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2586de4a",
   "metadata": {},
   "source": [
    "This is a way to compute accuracy of the model. Below is a function to compute accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df89db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(pred, y):\n",
    "    #select the top probability\n",
    "    top_pred = pred.argmax(1, keepdim = True)[:,0]\n",
    "    #compute number of correct predictions\n",
    "    correct = (top_pred==y).sum()\n",
    "    #compute accuracy\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f20f367",
   "metadata": {},
   "source": [
    "Let us print some images to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2168d00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's plot some images\n",
    "for img in range(5):\n",
    "    print(y_test[img])\n",
    "    img = x_test[img,:].reshape(sz,sz) \n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3a121b",
   "metadata": {},
   "source": [
    "Here, we will use the testing data (see x_test) and use neural network to make predictions (pred), and then test it against the ground truth (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcdbda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x = torch.tensor(x_test,dtype=torch.float32,device=device)\n",
    "    y = torch.tensor(y_test,dtype=torch.long,device=device)\n",
    "    \n",
    "    pred = model(x)\n",
    "    \n",
    "    acc = compute_accuracy(pred,y)\n",
    "\n",
    "    print(f\"test accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e71e3d-15f1-4c5a-b4e5-3f4a13fac101",
   "metadata": {},
   "source": [
    "So, the accuracy is the number above. Not bad. Eh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b5b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_pred = pred.argmax(1, keepdim = True)[:,0]\n",
    "print(top_pred)\n",
    "print(y_test)\n",
    "for j in range(len(y_test)):\n",
    "    print(\"number is %g and prediction is %g\" % (y_test[j], top_pred[j].float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca9832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "ba7e4ac6dd7c5001074f011d7f0799d4eb2d82671ff572ceb0cf0ca88fa15519"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
