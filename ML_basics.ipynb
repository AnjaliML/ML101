{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "  root =\"data\",\n",
    "  train = True,\n",
    "  download = True,\n",
    "  transform = ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets,\n",
    "test_data = datasets.FashionMNIST(\n",
    "  root=\"data\",\n",
    "  train = False,\n",
    "  download = True,\n",
    "  transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "shape of y: torch.Size([64]) <built-in method type of Tensor object at 0x17d15cb40>\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "  print(f\"shape of X [N, C, H, W]: {X.shape}\")\n",
    "  print(f\"shape of y: {y.shape} {y.type}\")\n",
    "  break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "  \"cuda\"\n",
    "  if torch.cuda.is_available()\n",
    "  else \"mps\"\n",
    "  if torch.backends.mps.is_available()\n",
    "  else \"cpu\"\n",
    "\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "  def __init__(self, *args, **kwargs) -> None:\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.linear_relu_stack = nn.Sequential(\n",
    "      nn.Linear(28*28, 512),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(512, 512),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(512,10)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.flatten(x)\n",
    "    logits = self.linear_relu_stack(x)\n",
    "    return logits\n",
    "  \n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.303643  [   64/60000]\n",
      "loss: 2.293945  [ 6464/60000]\n",
      "loss: 2.280457  [12864/60000]\n",
      "loss: 2.265203  [19264/60000]\n",
      "loss: 2.255441  [25664/60000]\n",
      "loss: 2.229511  [32064/60000]\n",
      "loss: 2.227628  [38464/60000]\n",
      "loss: 2.206151  [44864/60000]\n",
      "loss: 2.196387  [51264/60000]\n",
      "loss: 2.154268  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 2.166437 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.180491  [   64/60000]\n",
      "loss: 2.173079  [ 6464/60000]\n",
      "loss: 2.123580  [12864/60000]\n",
      "loss: 2.122919  [19264/60000]\n",
      "loss: 2.086372  [25664/60000]\n",
      "loss: 2.026135  [32064/60000]\n",
      "loss: 2.044775  [38464/60000]\n",
      "loss: 1.983426  [44864/60000]\n",
      "loss: 1.977143  [51264/60000]\n",
      "loss: 1.893721  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.3%, Avg loss: 1.911402 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.950596  [   64/60000]\n",
      "loss: 1.922688  [ 6464/60000]\n",
      "loss: 1.814858  [12864/60000]\n",
      "loss: 1.832815  [19264/60000]\n",
      "loss: 1.740941  [25664/60000]\n",
      "loss: 1.685168  [32064/60000]\n",
      "loss: 1.696065  [38464/60000]\n",
      "loss: 1.611810  [44864/60000]\n",
      "loss: 1.627666  [51264/60000]\n",
      "loss: 1.507161  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.9%, Avg loss: 1.540598 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.616785  [   64/60000]\n",
      "loss: 1.576048  [ 6464/60000]\n",
      "loss: 1.429451  [12864/60000]\n",
      "loss: 1.484566  [19264/60000]\n",
      "loss: 1.376922  [25664/60000]\n",
      "loss: 1.367919  [32064/60000]\n",
      "loss: 1.377817  [38464/60000]\n",
      "loss: 1.307929  [44864/60000]\n",
      "loss: 1.336349  [51264/60000]\n",
      "loss: 1.229332  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 1.264664 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.351059  [   64/60000]\n",
      "loss: 1.326210  [ 6464/60000]\n",
      "loss: 1.160708  [12864/60000]\n",
      "loss: 1.255762  [19264/60000]\n",
      "loss: 1.139809  [25664/60000]\n",
      "loss: 1.164123  [32064/60000]\n",
      "loss: 1.185809  [38464/60000]\n",
      "loss: 1.121732  [44864/60000]\n",
      "loss: 1.152661  [51264/60000]\n",
      "loss: 1.068399  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 1.095880 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors: what are these and how to use them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly from data\n",
    "data = [[1,2], [3,4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a Numpy array\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.3113, 0.7818],\n",
      "        [0.1021, 0.4849]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# From another tensor:\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.6078, 0.2804, 0.2838],\n",
      "        [0.6219, 0.1621, 0.0458]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#With random or constant values:\n",
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Tensor Attributes\n",
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Operations\n",
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "  tensor = tensor.to('cuda')\n",
    "  print(f\"Device tensor is stored on: {tensor.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Standard numpy-like indexing and slicing:\n",
    "tensor = torch.ones(4, 4)\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To join tensors, we can use torch.cat to concatenate a sequence of tensors along a specified dimension. Another tensor joining operation, torch.stack, is similar but subtly different from torch.cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.mul(tensor) \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor * tensor \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Multiplying Tensors\n",
    "# This computes the element-wise product\n",
    "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor * tensor \\n {tensor * tensor}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This computes the matrix multiplication between two tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.matmul(tensor.T) \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]]) \n",
      "\n",
      "tensor @ tensor.T \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **In-place operations** Operations that have a _ suffix are in-place. For example: x.copy_(Y), x.t_(), will change x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets & DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating and Visualizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Custom Dataset for your files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __ init __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __init__ is a special function used to set up newly created objects. It's part of a class definition and runs automatically when creating a new instance of the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The labels.csv file looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tshirt1.jpg, 0\n",
    "# tshirt2.jpg, 0\n",
    "\n",
    "# ankleboot999.jpg, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "    self.img_labels = pd.read_csv(annotations_file)\n",
    "    self.img_dir = img_dir\n",
    "    self.transform = transform\n",
    "    self.target_transform = target_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  __ len __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " __ len __ is a special method that defines how the len() function behaves for class instances. Implementing __ len __ in your class enables objects to be passed to len(), returning an integer representing the object's size or number of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "def __len__(self):\n",
    "    return len(self.img_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __ getitem __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __getitem__ method in Python is a special function that defines how elements are accessed using square brackets ([]). Implementing __getitem__ in your class enables instances to support indexing and slicing, similar to built-in data structures like lists, tuples, and dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __getitem__(self, idx):\n",
    "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "    image = read_image(img_path)\n",
    "    label = self.img_labels.iloc[idx, 1]\n",
    "    if self.transform:\n",
    "        image = self.transform(image)\n",
    "    if self.target_transform:\n",
    "        label = self.target_transform(label)\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing your data for training with DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through the Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data often requires preprocessing before it's suitable for training machine learning algorithms. Transforms help manipulate the data into the appropriate format.\n",
    "\n",
    "TorchVision datasets include two parameters: 'transform' for modifying features and 'target_transform' for altering labels. These accept callables containing transformation logic. The torchvision.transforms module provides many ready-to-use transforms.\n",
    "\n",
    "FashionMNIST features are in PIL Image format with integer labels. For training, we need normalized tensor features and one-hot encoded tensor labels. We use ToTensor and Lambda transforms to achieve these conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToTensor converts a PIL image or NumPy ndarray into a FloatTensor. and scales the image’s pixel intensity values in the range [0., 1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lambda Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, Lambda transforms apply custom, user-defined transformations to data within the torchvision.transforms module. This feature offers flexibility for preprocessing steps not covered by torchvision's standard transformations. The Lambda transform takes a function as an argument and applies it to each dataset element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_transform = Lambda(lambda y: torch.zeros(\n",
    "    10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A  neural network consists of interconnected nodes (neurons) that process and learn from data through weighted connections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `torch.nn` is a module in PyTorch that provides essential tools for building and training neural networks. It includes pre-defined layers, loss functions, and utilities to streamline the creation, customization, and optimization of deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Device for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([8])\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let’s break down the layers in the FashionMNIST model. To illustrate it, we will take a sample minibatch of 3 images of size 28x28 and see what happens to it as we pass it through the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Flatten, nn.Linear, nn.ReLU, nn.Sequential, nn.Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Flatten converts multi-dimensional input tensors into 1-dimensional tensors in neural networks, particularly in PyTorch.\n",
    "\n",
    "nn.Linear, also called a fully connected or dense layer, is a key component in neural networks. It performs linear transformations on input data, mapping it to an output space.\n",
    "\n",
    "nn.ReLU (Rectified Linear Unit) is a popular activation function that introduces non-linearity into neural networks, essential for learning complex patterns.\n",
    "\n",
    "nn.Sequential is a PyTorch container module that allows stacking layers in order, useful for building simple feed-forward neural networks where each layer's output becomes the next layer's input.\n",
    "\n",
    "nn.Softmax is an activation function used in the final layer of classification models. It transforms raw output scores (logits) into probabilities, making them easier to interpret and use for decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n",
      "torch.Size([3, 20])\n",
      "Before ReLU:  tensor([[-0.3264,  0.2045, -0.2844, -0.4914, -0.1212,  0.0925, -0.5322, -0.4351,\n",
      "          0.0932,  0.3811, -0.0162,  0.0242, -0.5544,  0.7543,  0.3187, -0.1645,\n",
      "          0.5500,  0.6467,  0.1858,  0.0836],\n",
      "        [-0.0144,  0.4569, -0.6450, -0.4188, -0.4306,  0.4422, -0.4905, -0.3342,\n",
      "          0.3966,  0.1537,  0.3626,  0.3200, -0.3123,  0.6153,  0.3389, -0.3378,\n",
      "          0.5751,  0.7267,  0.5071,  0.3118],\n",
      "        [-0.1139,  0.3702, -0.2975, -0.4764,  0.0751,  0.3665, -0.4987, -0.4759,\n",
      "          0.2069,  0.3965, -0.2714,  0.1578, -0.3417,  0.4921,  0.0848, -0.3314,\n",
      "          0.5995,  0.5459,  0.1521,  0.1647]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.2045, 0.0000, 0.0000, 0.0000, 0.0925, 0.0000, 0.0000, 0.0932,\n",
      "         0.3811, 0.0000, 0.0242, 0.0000, 0.7543, 0.3187, 0.0000, 0.5500, 0.6467,\n",
      "         0.1858, 0.0836],\n",
      "        [0.0000, 0.4569, 0.0000, 0.0000, 0.0000, 0.4422, 0.0000, 0.0000, 0.3966,\n",
      "         0.1537, 0.3626, 0.3200, 0.0000, 0.6153, 0.3389, 0.0000, 0.5751, 0.7267,\n",
      "         0.5071, 0.3118],\n",
      "        [0.0000, 0.3702, 0.0000, 0.0000, 0.0751, 0.3665, 0.0000, 0.0000, 0.2069,\n",
      "         0.3965, 0.0000, 0.1578, 0.0000, 0.4921, 0.0848, 0.0000, 0.5995, 0.5459,\n",
      "         0.1521, 0.1647]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "flatten =  nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())\n",
    "#nn.Linear \n",
    "layer1 = nn.Linear (in_features=28*28, out_features = 20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())\n",
    "#nn.ReLU \n",
    "print(f\"Before ReLU:  {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")\n",
    "#nn.Sequential \n",
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)\n",
    "#nn.Softmax\n",
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0222,  0.0123, -0.0129,  ..., -0.0325, -0.0223, -0.0179],\n",
      "        [-0.0140,  0.0023,  0.0340,  ..., -0.0356,  0.0184, -0.0194]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0051,  0.0109], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0049,  0.0060,  0.0289,  ..., -0.0018,  0.0399, -0.0032],\n",
      "        [ 0.0007,  0.0043,  0.0098,  ..., -0.0324, -0.0035,  0.0187]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0306, -0.0433], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0255, -0.0216, -0.0087,  ..., -0.0235,  0.0323,  0.0042],\n",
      "        [ 0.0244, -0.0316,  0.0187,  ..., -0.0285, -0.0291, -0.0022]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0088, -0.0090], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "  print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Differentiation with torch.autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.ones(5) # input tensor\n",
    "y = torch.zeros(3) # expected output\n",
    "w = torch.randn(5, 3, requires_grad= True)\n",
    "b = torch.randn(3, requires_grad = True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x308fff850>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x309329d50>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradient function for z = {z.grad_fn}\")\n",
    "print(f\"Gradient function for loss = {loss.grad_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1705, 0.2581, 0.0210],\n",
      "        [0.1705, 0.2581, 0.0210],\n",
      "        [0.1705, 0.2581, 0.0210],\n",
      "        [0.1705, 0.2581, 0.0210],\n",
      "        [0.1705, 0.2581, 0.0210]])\n",
      "tensor([0.1705, 0.2581, 0.0210])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    " We can only obtain the grad properties for the leaf nodes of the computational graph, which have requires_grad property set to True. For all other nodes in our graph, gradients will not be available.\n",
    "\n",
    "We can only perform gradient calculations using backward once on a given graph, for performance reasons. If we need to do several backward calls on the same graph, we need to pass retain_graph=True to the backward call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disabling Gradient Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, all tensors with requires_grad=True track their computational history and support gradient computation. However, in some cases, such as when applying a trained model to input data, we only need forward computations through the network. To stop tracking computations, we can wrap our code in a torch.no_grad() block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x,w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "  z = torch.matmul(x,w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Another way to achieve the same result is to use the detach() method on the tensor:\n",
    "z = torch.matmul(x,w)+b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Reading: Tensor Gradients and Jacobian Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call\n",
      "tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.]])\n",
      "\n",
      "Second call\n",
      "tensor([[8., 4., 4., 4., 4.],\n",
      "        [4., 8., 4., 4., 4.],\n",
      "        [4., 4., 8., 4., 4.],\n",
      "        [4., 4., 4., 8., 4.]])\n",
      "\n",
      "Call after zeroing gradients\n",
      "tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.]])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.eye(4, 5, requires_grad=True)\n",
    "out = (inp+1).pow(2).t()\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"First call\\n{inp.grad}\")\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"\\nSecond call\\n{inp.grad}\")\n",
    "inp.grad.zero_()\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"\\nCall after zeroing gradients\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisite Code\n",
    "# we load the code from the previous sections on Datasets and Data Loaders and Build Model.\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Implementation\n",
    "We define train_loop that loops over our optimization code, and test_loop that evaluates the model’s performance against our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the loss function and optimizer, and pass it to train_loop and test_loop. Feel free to increase the number of epochs to track the model’s improving performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.301539  [   64/60000]\n",
      "loss: 2.289985  [ 6464/60000]\n",
      "loss: 2.278532  [12864/60000]\n",
      "loss: 2.271997  [19264/60000]\n",
      "loss: 2.235570  [25664/60000]\n",
      "loss: 2.215268  [32064/60000]\n",
      "loss: 2.213233  [38464/60000]\n",
      "loss: 2.177849  [44864/60000]\n",
      "loss: 2.176032  [51264/60000]\n",
      "loss: 2.145626  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 50.6%, Avg loss: 2.138972 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.147517  [   64/60000]\n",
      "loss: 2.137679  [ 6464/60000]\n",
      "loss: 2.080538  [12864/60000]\n",
      "loss: 2.096019  [19264/60000]\n",
      "loss: 2.030731  [25664/60000]\n",
      "loss: 1.976007  [32064/60000]\n",
      "loss: 1.994684  [38464/60000]\n",
      "loss: 1.913609  [44864/60000]\n",
      "loss: 1.914102  [51264/60000]\n",
      "loss: 1.844186  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Avg loss: 1.842278 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.878593  [   64/60000]\n",
      "loss: 1.849953  [ 6464/60000]\n",
      "loss: 1.727505  [12864/60000]\n",
      "loss: 1.766215  [19264/60000]\n",
      "loss: 1.652912  [25664/60000]\n",
      "loss: 1.612660  [32064/60000]\n",
      "loss: 1.625963  [38464/60000]\n",
      "loss: 1.536497  [44864/60000]\n",
      "loss: 1.555703  [51264/60000]\n",
      "loss: 1.455592  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.1%, Avg loss: 1.475139 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.545245  [   64/60000]\n",
      "loss: 1.516777  [ 6464/60000]\n",
      "loss: 1.364835  [12864/60000]\n",
      "loss: 1.434043  [19264/60000]\n",
      "loss: 1.319282  [25664/60000]\n",
      "loss: 1.316594  [32064/60000]\n",
      "loss: 1.327877  [38464/60000]\n",
      "loss: 1.262088  [44864/60000]\n",
      "loss: 1.291189  [51264/60000]\n",
      "loss: 1.197827  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 1.224305 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.301986  [   64/60000]\n",
      "loss: 1.291221  [ 6464/60000]\n",
      "loss: 1.122806  [12864/60000]\n",
      "loss: 1.225674  [19264/60000]\n",
      "loss: 1.109686  [25664/60000]\n",
      "loss: 1.126829  [32064/60000]\n",
      "loss: 1.149748  [38464/60000]\n",
      "loss: 1.094231  [44864/60000]\n",
      "loss: 1.128028  [51264/60000]\n",
      "loss: 1.048643  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 1.070209 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.140354  [   64/60000]\n",
      "loss: 1.151094  [ 6464/60000]\n",
      "loss: 0.963671  [12864/60000]\n",
      "loss: 1.096610  [19264/60000]\n",
      "loss: 0.982201  [25664/60000]\n",
      "loss: 0.999390  [32064/60000]\n",
      "loss: 1.039913  [38464/60000]\n",
      "loss: 0.988287  [44864/60000]\n",
      "loss: 1.020888  [51264/60000]\n",
      "loss: 0.954738  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.5%, Avg loss: 0.970432 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.027372  [   64/60000]\n",
      "loss: 1.059488  [ 6464/60000]\n",
      "loss: 0.854092  [12864/60000]\n",
      "loss: 1.010748  [19264/60000]\n",
      "loss: 0.901941  [25664/60000]\n",
      "loss: 0.909101  [32064/60000]\n",
      "loss: 0.967667  [38464/60000]\n",
      "loss: 0.919046  [44864/60000]\n",
      "loss: 0.946278  [51264/60000]\n",
      "loss: 0.890569  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.901817 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.943448  [   64/60000]\n",
      "loss: 0.994927  [ 6464/60000]\n",
      "loss: 0.775093  [12864/60000]\n",
      "loss: 0.949722  [19264/60000]\n",
      "loss: 0.848091  [25664/60000]\n",
      "loss: 0.842585  [32064/60000]\n",
      "loss: 0.916216  [38464/60000]\n",
      "loss: 0.872080  [44864/60000]\n",
      "loss: 0.892471  [51264/60000]\n",
      "loss: 0.843383  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 0.851999 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.878337  [   64/60000]\n",
      "loss: 0.945810  [ 6464/60000]\n",
      "loss: 0.715806  [12864/60000]\n",
      "loss: 0.903796  [19264/60000]\n",
      "loss: 0.809529  [25664/60000]\n",
      "loss: 0.792748  [32064/60000]\n",
      "loss: 0.876678  [38464/60000]\n",
      "loss: 0.838570  [44864/60000]\n",
      "loss: 0.851909  [51264/60000]\n",
      "loss: 0.806655  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.4%, Avg loss: 0.813881 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.825988  [   64/60000]\n",
      "loss: 0.905905  [ 6464/60000]\n",
      "loss: 0.669520  [12864/60000]\n",
      "loss: 0.867769  [19264/60000]\n",
      "loss: 0.779993  [25664/60000]\n",
      "loss: 0.754563  [32064/60000]\n",
      "loss: 0.844181  [38464/60000]\n",
      "loss: 0.813392  [44864/60000]\n",
      "loss: 0.820240  [51264/60000]\n",
      "loss: 0.776732  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.6%, Avg loss: 0.783279 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and Load the Model\n",
    "In this section we will look at how to persist model state with saving, loading and running model predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Model Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch models store the learned parameters in an internal state dictionary, called state_dict. These can be persisted via the torch.save method:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /Users/anjalisuman/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:06<00:00, 85.7MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = models.vgg16(weights='IMAGENET1K_V1')\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load model weights, you need to create an instance of the same model first, and then load the parameters using load_state_dict() method.\n",
    "\n",
    "In the code below, we set weights_only=True to limit the functions executed during unpickling to only those necessary for loading weights. Using weights_only=True is considered a best practice when loading weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16() # we do not specify ``weights``, i.e. create untrained model\n",
    "model.load_state_dict(torch.load('model_weights.pth', weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "be sure to call model.eval() method before inferencing to set the dropout and batch normalization layers to evaluation mode. Failing to do this will yield inconsistent inference results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Models with Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading model weights, we needed to instantiate the model class first, because the class defines the structure of a network. We might want to save the structure of this class together with the model, in which case we can pass model (and not model.state_dict()) to the saving function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then load the model as demonstrated below.\n",
    "\n",
    "As described in Saving and loading torch.nn.Modules, saving state_dict``s is considered the best practice. However, below we use ``weights_only=False because this involves loading the model, which is a legacy use case for torch.save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pth', weights_only=False),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "This approach uses Python pickle module when serializing the model, thus it relies on the actual class definition to be available when loading the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few basic tensor manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "z = torch.zeros(5,3)\n",
    "print(z)\n",
    "print(z.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a 5x3 matrix filled with zeros, and query its datatype to find out that the zeros are 32-bit floating point numbers, whoich is the default Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you wanted integers instead? You can always override the default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "i = torch.ones((5,3), dtype=torch.int16)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A random tensor:\n",
      "tensor([[0.3126, 0.3791],\n",
      "        [0.3087, 0.0736]])\n",
      "\n",
      "A different random tensor:\n",
      "tensor([[0.4216, 0.0691],\n",
      "        [0.2332, 0.4047]])\n",
      "\n",
      "Should match r1:\n",
      "tensor([[0.3126, 0.3791],\n",
      "        [0.3087, 0.0736]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1729)\n",
    "r1 = torch.rand(2, 2)\n",
    "print('A random tensor:')\n",
    "print(r1)\n",
    "\n",
    "r2 = torch.rand(2, 2)\n",
    "print('\\nA different random tensor:')\n",
    "print(r2) # new values\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "r3 = torch.rand(2, 2)\n",
    "print('\\nShould match r1:')\n",
    "print(r3) # repeat values of r1 because of re-seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch tensors perform arithmetic operations intuitively. Tensors of similar shapes may be added, multiplied, etc. Operations with scalars are distributed over the tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "ones = torch.ones(2,3)\n",
    "print(ones)\n",
    "\n",
    "twos = torch.ones(2, 3)* 2 # every element is multiplied by 2\n",
    "print(twos)\n",
    "\n",
    "threes = ones+twos # addition allowed because shapes are similar\n",
    "print(threes) # tensors are added element-wise\n",
    "print(threes.shape) # this has the same dimensions as input tensors\n",
    "\n",
    "r1 = torch.rand(2, 3)\n",
    "r2 = torch.rand(3, 2)\n",
    "# uncomment this line to get a run time error\n",
    "# r3 = r1 + r2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a small sample of the mathematical operations available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A random matrix, r:\n",
      "tensor([[-0.2629, -0.1986],\n",
      "        [ 0.4439,  0.6434]])\n",
      "\n",
      "Absolute value of r:\n",
      "tensor([[0.2629, 0.1986],\n",
      "        [0.4439, 0.6434]])\n",
      "\n",
      "Inverse sine of r:\n",
      "tensor([[-0.2660, -0.1999],\n",
      "        [ 0.4600,  0.6989]])\n",
      "\n",
      "Determinant of r:\n",
      "tensor(-0.0810)\n",
      "\n",
      "Singular value decomposition of r:\n",
      "torch.return_types.svd(\n",
      "U=tensor([[-0.3764,  0.9265],\n",
      "        [ 0.9265,  0.3764]]),\n",
      "S=tensor([0.8428, 0.0961]),\n",
      "V=tensor([[ 0.6054, -0.7959],\n",
      "        [ 0.7959,  0.6054]]))\n",
      "\n",
      "Average and standard deviation of r:\n",
      "(tensor(0.4552), tensor(0.1565))\n",
      "\n",
      "Maximum value of r:\n",
      "tensor(0.6434)\n"
     ]
    }
   ],
   "source": [
    "r = (torch.rand(2, 2) - 0.5) * 2 # values between -1 and 1\n",
    "print('A random matrix, r:')\n",
    "print(r)\n",
    "\n",
    "# Common mathematical operations are supported:\n",
    "print('\\nAbsolute value of r:')\n",
    "print(torch.abs(r))\n",
    "\n",
    "#...as are trigonometric functions:\n",
    "print('\\nInverse sine of r:')\n",
    "print(torch.asin(r))\n",
    "\n",
    "#...and linear algebra operations like determinant and singular value decomposition \n",
    "print('\\nDeterminant of r:')\n",
    "print(torch.det(r))\n",
    "print('\\nSingular value decomposition of r:')\n",
    "print(torch.svd(r))\n",
    "\n",
    "#...and statistical and aggregate operations:\n",
    "print('\\nAverage and standard deviation of r:')\n",
    "print(torch.std_mean(r))\n",
    "print('\\nMaximum value of r:')\n",
    "print(torch.max(r))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking over this code, you should be able to spot some structural similarities with the diagram above.\n",
    "\n",
    "This demonstrates the structure of a typical PyTorch model:\n",
    "\n",
    "It inherits from torch.nn.Module - modules may be nested - in fact, even the Conv2d and Linear layer classes inherit from torch.nn.Module.\n",
    "\n",
    "A model will have an __init__() function, where it instantiates its layers, and loads any data artifacts it might need (e.g., an NLP model might load a vocabulary).\n",
    "\n",
    "A model will have a forward() function. This is where the actual computation happens: An input is passed through the network layers and various functions to generate an output.\n",
    "\n",
    "Other than that, you can build out your model class like any other Python class, adding whatever properties and methods you need to support your model’s computation.\n",
    "\n",
    "Let’s instantiate this object and run a sample input through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "Image batch shape:\n",
      "torch.Size([1, 1, 32, 32])\n",
      "\n",
      "Raw output:\n",
      "tensor([[ 0.0079,  0.0452, -0.0448,  0.0572,  0.0418,  0.0428, -0.0063,  0.1045,\n",
      "          0.0045, -0.0551]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "print(net)                         # what does the object tell us about itself?\n",
    "\n",
    "input = torch.rand(1, 1, 32, 32)   # stand-in for a 32x32 black & white image\n",
    "print('\\nImage batch shape:')\n",
    "print(input.shape)\n",
    "\n",
    "output = net(input)                # we don't call forward() directly\n",
    "print('\\nRaw output:')\n",
    "print(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few important things happening above:\n",
    "\n",
    "First, we instantiate the LeNet class, and we print the net object. A subclass of torch.nn.Module will report the layers it has created and their shapes and parameters. This can provide a handy overview of a model if you want to get the gist of its processing.\n",
    "\n",
    "Below that, we create a dummy input representing a 32x32 image with 1 color channel. Normally, you would load an image tile and convert it to a tensor of this shape.\n",
    "\n",
    "You may have noticed an extra dimension to our tensor - the batch dimension. PyTorch models assume they are working on batches of data - for example, a batch of 16 of our image tiles would have the shape (16, 1, 32, 32). Since we’re only using one image, we create a batch of 1 with shape (1, 1, 32, 32).\n",
    "\n",
    "We ask the model for an inference by calling it like a function: net(input). The output of this call represents the model’s confidence that the input represents a particular digit. (Since this instance of the model hasn’t learned anything yet, we shouldn’t expect to see any signal in the output.) Looking at the shape of output, we can see that it also has a batch dimension, the size of which should always match the input batch dimension. If we had passed in an input batch of 16 instances, output would have a shape of (16, 10).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we’re going to demonstrate using one of the ready-to-download, open-access datasets from TorchVision, how to transform the images for consumption by your model, and how to use the DataLoader to feed batches of data to your model.\n",
    "\n",
    "The first thing we need to do is transform our incoming images into a PyTorch tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we specify two transformations for our input:\n",
    "\n",
    "transforms.ToTensor() converts images loaded by Pillow into PyTorch tensors.\n",
    "\n",
    "transforms.Normalize() adjusts the values of the tensor so that their average is zero and their standard deviation is 1.0. Most activation functions have their strongest gradients around x = 0, so centering our data there can speed learning. The values passed to the transform are the means (first tuple) and the standard deviations (second tuple) of the rgb values of the images in the dataset. You can calculate these values yourself by running these few lines of code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from torch.utils.data import ConcatDataset transform = transforms.Compose([transforms.ToTensor()]) trainset = torchvision.datasets.CIFAR10(root=’./data’, train=True,\n",
    "\n",
    "download=True, transform=transform)\n",
    "\n",
    "#stack all train images together into a tensor of shape #(50000, 3, 32, 32) x = torch.stack([sample[0] for sample in ConcatDataset([trainset])])\n",
    "\n",
    "#get the mean of each channel mean = torch.mean(x, dim=(0,2,3)) #tensor([0.4914, 0.4822, 0.4465]) std = torch.std(x, dim=(0,2,3)) #tensor([0.2470, 0.2435, 0.2616])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more transforms available, including cropping, centering, rotation, and reflection.\n",
    "\n",
    "Next, we’ll create an instance of the CIFAR10 dataset. This is a set of 32x32 color image tiles representing 10 classes of objects: 6 of animals (bird, cat, deer, dog, frog, horse) and 4 of vehicles (airplane, automobile, ship, truck):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [02:05<00:00, 1354593.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root= './data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of creating a dataset object in PyTorch. Downloadable datasets (like CIFAR-10 above) are subclasses of torch.utils.data.Dataset. Dataset classes in PyTorch include the downloadable datasets in TorchVision, Torchtext, and TorchAudio, as well as utility dataset classes such as torchvision.datasets.ImageFolder, which will read a folder of labeled images. You can also create your own subclasses of Dataset.\n",
    "\n",
    "When we instantiate our dataset, we need to tell it a few things:\n",
    "\n",
    "The filesystem path to where we want the data to go.\n",
    "\n",
    "Whether or not we are using this set for training; most datasets will be split into training and test subsets.\n",
    "\n",
    "Whether we would like to download the dataset if we haven’t already.\n",
    "\n",
    "The transformations we want to apply to the data.\n",
    "\n",
    "Once your dataset is ready, you can give it to the DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A  Dataset subclass wraps access to the data, and is specialized to the type of data it’s serving. The DataLoader knows nothing about the data, but organizes the input tensors served by the Dataset into batches with the parameters you specify.\n",
    "\n",
    "In the example above, we’ve asked a DataLoader to give us batches of 4 images from trainset, randomizing their order (shuffle=True), and we told it to spin up two workers to load data from disk.\n",
    "\n",
    "It’s good practice to visualize the batches your DataLoader serves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  car  ship  ship horse\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Your PyTorch Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put all the pieces together, and train a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll need training and test datasets. If you haven't already, run the cell below to make sure the dataset is downloaded. (It may take a minute.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root= './data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll run our check on the output from DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck   cat  ship  bird\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#functions to show an image\n",
    "\n",
    "def imshow(img):\n",
    "  img = img/ 2 + 0.5  # unnormalize\n",
    "  npimg = img.numpy()\n",
    "  plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "\n",
    "#get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "#show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "#print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the model we'll train.If it looks familiar, that's because it's a variant of LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last ingredients we need are a loss function and an optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function, as discussed earlier in this video, is a measure of how far from our ideal output the model’s prediction was. Cross-entropy loss is a typical loss function for classification models like ours.\n",
    "\n",
    "The optimizer is what drives the learning. Here we have created an optimizer that implements stochastic gradient descent, one of the more straightforward optimization algorithms. Besides parameters of the algorithm, like the learning rate (lr) and momentum, we also pass in net.parameters(), which is a collection of all the learning weights in the model - which is what the optimizer adjusts.\n",
    "\n",
    "Finally, all of this is assembled into the training loop. Go ahead and run this cell, as it will likely take a few minutes to execute:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.233\n",
      "[1,  4000] loss: 1.898\n",
      "[1,  6000] loss: 1.681\n",
      "[1,  8000] loss: 1.564\n",
      "[1, 10000] loss: 1.535\n",
      "[1, 12000] loss: 1.472\n",
      "[2,  2000] loss: 1.406\n",
      "[2,  4000] loss: 1.375\n",
      "[2,  6000] loss: 1.358\n",
      "[2,  8000] loss: 1.316\n",
      "[2, 10000] loss: 1.299\n",
      "[2, 12000] loss: 1.282\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): # loop over the dataset multiple times\n",
    "\n",
    "\n",
    "  running_loss = 0.0\n",
    "  for i, data in enumerate(trainloader, 0):\n",
    "    #get the inputs\n",
    "    inputs, labels = data\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    #forward+ backward + optimize\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    if i % 2000 == 1999: #print every 2000 mini-batches\n",
    "      print('[%d, %5d] loss: %.3f' %(epoch + 1, i+1, running_loss / 2000))\n",
    "      running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are doing only 2 training epochs (line 1) - that is, two passes over the training dataset. Each pass has an inner loop that iterates over the training data (line 4), serving batches of transformed input images and their correct labels.\n",
    "\n",
    "Zeroing the gradients (line 9) is an important step. Gradients are accumulated over a batch; if we do not reset them for every batch, they will keep accumulating, which will provide incorrect gradient values, making learning impossible.\n",
    "\n",
    "In line 12, we ask the model for its predictions on this batch. In the following line (13), we compute the loss - the difference between outputs (the model prediction) and labels (the correct output).\n",
    "\n",
    "In line 14, we do the backward() pass, and calculate the gradients that will direct the learning.\n",
    "\n",
    "In line 15, the optimizer performs one learning step - it uses the gradients from the backward() call to nudge the learning weights in the direction it thinks will reduce the loss.\n",
    "\n",
    "The remainder of the loop does some light reporting on the epoch number, how many training instances have been completed, and what the collected loss is over the training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the loss is monotonically descending, indicating that our model is continuing to improve its performance on the training dataset.\n",
    "\n",
    "As a final step, we should check that the model is actually doing general learning, and not simply “memorizing” the dataset. This is called overfitting, and usually indicates that the dataset is too small (not enough examples for general learning), or that the model has more learning parameters than it needs to correctly model the dataset.\n",
    "\n",
    "This is the reason datasets are split into training and test subsets - to test the generality of the model, we ask it to make predictions on data it hasn’t trained on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 54 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you followed along, you should see that the model is roughly 50% accurate at this point. That’s not exactly state-of-the-art, but it’s far better than the 10% accuracy we’d expect from a random output. This demonstrates that some general learning did happen in the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to PyTorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors are the central data abstraction in PyTorch. This interactive notebook provides an in-depth introduction to the torch.Tensor class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, let's import the PyTorch module.We'll also add Python's math module to facilitate some of the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to create a tensor is with the torch.empty() call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3,4)\n",
    "print(type(x))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s unpack what we just did:\n",
    "\n",
    "We created a tensor using one of the numerous factory methods attached to the torch module.\n",
    "\n",
    "The tensor itself is 2-dimensional, having 3 rows and 4 columns.\n",
    "\n",
    "The type of the object returned is torch.Tensor, which is an alias for torch.FloatTensor; by default, PyTorch tensors are populated with 32-bit floating point numbers. (More on data types below.)\n",
    "\n",
    "You will probably see some random-looking values when printing your tensor. The torch.empty() call allocates memory for the tensor, but does not initialize it with any values - so what you’re seeing is whatever was in memory at the time of allocation.\n",
    "\n",
    "A brief note about tensors and their number of dimensions, and terminology:\n",
    "\n",
    "You will sometimes see a 1-dimensional tensor called a vector.\n",
    "\n",
    "Likewise, a 2-dimensional tensor is often referred to as a matrix.\n",
    "\n",
    "Anything with more than two dimensions is generally just called a tensor.\n",
    "\n",
    "More often than not, you’ll want to initialize your tensor with some value. Common cases are all zeros, all ones, or random values, and the torch module provides factory methods for all of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n"
     ]
    }
   ],
   "source": [
    "zeros = torch.zeros(2, 3)\n",
    "print(zeros)\n",
    "\n",
    "ones = torch.ones(2, 3)\n",
    "print(ones)\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "random = torch.rand(2,3)\n",
    "print(random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The factory methods all do just what you’d expect - we have a tensor full of zeros, another full of ones, and another with random values between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Tensors and Seeding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaking of the random tensor, did you notice the call to torch.manual_seed() immediately preceding it? Initializing tensors, such as a model’s learning weights, with random values is common but there are times - especially in research settings - where you’ll want some assurance of the reproducibility of your results. Manually setting your random number generator’s seed is the way to do this. Let’s look more closely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1729)\n",
    "random1 = torch.rand(2, 3)\n",
    "print(random1)\n",
    "\n",
    "random2 = torch.rand(2, 3)\n",
    "print(random2)\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "random3 = torch.rand(2, 3)\n",
    "print(random3)\n",
    "\n",
    "random4 = torch.rand(2, 3)\n",
    "print(random4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you should see above is that random1 and random3 carry identical values, as do random2 and random4. Manually setting the RNG’s seed resets it, so that identical computations depending on random number should, in most settings, provide identical results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, when you’re performing operations on two or more tensors, they will need to be of the same shape - that is, having the same number of dimensions and the same number of cells in each dimension. For that, we have the torch.*_like() methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0.6128, 0.1519, 0.0453],\n",
      "         [0.5035, 0.9978, 0.3884]],\n",
      "\n",
      "        [[0.6929, 0.1703, 0.1384],\n",
      "         [0.4759, 0.7481, 0.0361]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(2, 2, 3)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "\n",
    "empty_like_x = torch.empty_like(x)\n",
    "print(empty_like_x.shape)\n",
    "print(empty_like_x)\n",
    "\n",
    "zeros_like_x = torch.zeros_like(x)\n",
    "print(zeros_like_x.shape)\n",
    "print(zeros_like_x)\n",
    "\n",
    "ones_like_x = torch.ones_like(x)\n",
    "print(ones_like_x.shape)\n",
    "print(ones_like_x)\n",
    "\n",
    "rand_like_x = torch.rand_like(x)\n",
    "print(rand_like_x.shape)\n",
    "print(rand_like_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first new thing in the code cell above is the use of the .shape property on a tensor. This property contains a list of the extent of each dimension of a tensor - in our case, x is a three-dimensional tensor with shape 2 x 2 x 3.\n",
    "\n",
    "Below that, we call the .empty_like(), .zeros_like(), .ones_like(), and .rand_like() methods. Using the .shape property, we can verify that each of these methods returns a tensor of identical dimensionality and extent.\n",
    "\n",
    "The last way to create a tensor that will cover is to specify its data directly from a PyTorch collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.1416, 2.7183],\n",
      "        [1.6180, 0.0073]])\n",
      "tensor([ 2,  3,  5,  7, 11, 13, 17, 19])\n",
      "tensor([[2, 4, 6],\n",
      "        [3, 6, 9]])\n"
     ]
    }
   ],
   "source": [
    "some_constants = torch.tensor([[3.1415926, 2.71828], [1.61803, 0.0072897]])\n",
    "print(some_constants)\n",
    "\n",
    "some_integers = torch.tensor((2, 3, 5, 7, 11, 13, 17, 19))\n",
    "print(some_integers)\n",
    "\n",
    "more_integers = torch.tensor(((2, 4, 6), [3, 6, 9]))\n",
    "print(more_integers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using torch.tensor() is the most straightforward way to create a tensor if you already have data in a Python tuple or list. As shown above, nesting the collections will result in a multi-dimensional tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the datatype of a tensor is possible a couple of ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int16)\n",
      "tensor([[10.1244, 16.9389,  5.1768],\n",
      "        [ 5.4131,  8.2296, 13.6772]])\n",
      "tensor([[10, 16,  5],\n",
      "        [ 5,  8, 13]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((2, 3), dtype=torch.int16)\n",
    "print(a)\n",
    "\n",
    "b = torch.rand((2, 3), dtype=torch.float) * 20.\n",
    "print(b)\n",
    "\n",
    "c = b.to(torch.int32)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to set the underlying data type of a tensor is with an optional argument at creation time. In the first line of the cell above, we set dtype=torch.int16 for the tensor a. When we print a, we can see that it’s full of 1 rather than 1. - Python’s subtle cue that this is an integer type rather than floating point.\n",
    "\n",
    "Another thing to notice about printing a is that, unlike when we left dtype as the default (32-bit floating point), printing the tensor also specifies its dtype.\n",
    "\n",
    "You may have also spotted that we went from specifying the tensor’s shape as a series of integer arguments, to grouping those arguments in a tuple. This is not strictly necessary - PyTorch will take a series of initial, unlabeled integer arguments as a tensor shape - but when adding the optional arguments, it can make your intent more readable.\n",
    "\n",
    "The other way to set the datatype is with the .to() method. In the cell above, we create a random floating point tensor b in the usual way. Following that, we create c by converting b to a 32-bit integer with the .to() method. Note that c contains all the same values as b, but truncated to integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math & Logic with PyTorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know some of the ways to create a tensor… what can you do with them?\n",
    "\n",
    "Let’s look at basic arithmetic first, and how tensors interact with simple scalars:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[4., 4.],\n",
      "        [4., 4.]])\n",
      "tensor([[1.4142, 1.4142],\n",
      "        [1.4142, 1.4142]])\n"
     ]
    }
   ],
   "source": [
    "ones = torch.zeros(2, 2) + 1\n",
    "twos = torch.ones(2, 2) * 2\n",
    "threes = (torch.ones(2, 2) * 7 - 1)/2\n",
    "fours = twos ** 2\n",
    "sqrt2s = twos ** 0.5\n",
    "\n",
    "print(ones)\n",
    "print(twos)\n",
    "print(threes)\n",
    "print(fours)\n",
    "print(sqrt2s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, arithmetic operations between tensors and scalars, such as addition, subtraction, multiplication, division, and exponentiation are distributed over every element of the tensor. Because the output of such an operation will be a tensor, you can chain them together with the usual operator precedence rules, as in the line where we create threes.\n",
    "\n",
    "Similar operations between two tensors also behave like you’d intuitively expect:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  4.],\n",
      "        [ 8., 16.]])\n",
      "tensor([[5., 5.],\n",
      "        [5., 5.]])\n",
      "tensor([[12., 12.],\n",
      "        [12., 12.]])\n"
     ]
    }
   ],
   "source": [
    "powers2 = twos ** torch.tensor([[1, 2], [3, 4]])\n",
    "print(powers2)\n",
    "\n",
    "fives = ones + fours\n",
    "print(fives)\n",
    "\n",
    "dozens = threes * fours\n",
    "print(dozens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s important to note here that all of the tensors in the previous code cell were of identical shape. What happens when we try to perform a binary operation on tensors if dissimilar shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      4\u001b[0m b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(a\u001b[38;5;241m+\u001b[39mb)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# The following cell throws a run-time error. This is intentional\n",
    "\n",
    "a = torch.rand(2, 3)\n",
    "b = torch.rand(3, 2)\n",
    "\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the general case, you cannot operate on tensors of different shape this way, even in a case like the cell above, where the tensors have an identical number of elements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Brief: Tensor Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are familiar with broadcasting semantics in Numpy ndarrays, you'll find the same rules apply here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exception to the same-shapes rule is tensor broadcasting. here's an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6865, 0.3614, 0.6493, 0.2633],\n",
      "        [0.4762, 0.0548, 0.2024, 0.5731]])\n",
      "tensor([[1.3730, 0.7228, 1.2987, 0.5266],\n",
      "        [0.9524, 0.1096, 0.4049, 1.1461]])\n"
     ]
    }
   ],
   "source": [
    "rand = torch.rand(2, 4)\n",
    "doubled = rand * (torch.ones(1,4) * 2)\n",
    "\n",
    "print(rand)\n",
    "print(doubled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What’s the trick here? How is it we got to multiply a 2x4 tensor by a 1x4 tensor?\n",
    "\n",
    "Broadcasting is a way to perform an operation between tensors that have similarities in their shapes. In the example above, the one-row, four-column tensor is multiplied by both rows of the two-row, four-column tensor.\n",
    "\n",
    "This is an important operation in Deep Learning. The common example is multiplying a tensor of learning weights by a batch of input tensors, applying the operation to each instance in the batch separately, and returning a tensor of identical shape - just like our (2, 4) * (1, 4) example above returned a tensor of shape (2, 4).\n",
    "\n",
    "The rules for broadcasting are:\n",
    "\n",
    "Each tensor must have at least one dimension - no empty tensors.\n",
    "\n",
    "Comparing the dimension sizes of the two tensors, going from last to first:\n",
    "\n",
    "Each dimension must be equal, or\n",
    "\n",
    "One of the dimensions must be of size 1, or\n",
    "\n",
    "The dimension does not exist in one of the tensors\n",
    "\n",
    "Tensors of identical shape, of course, are trivially “broadcastable”, as you saw earlier.\n",
    "\n",
    "Here are some examples of situations that honor the above rules and allow broadcasting:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7191, 0.4067],\n",
      "         [0.7301, 0.6276],\n",
      "         [0.7357, 0.0381]],\n",
      "\n",
      "        [[0.7191, 0.4067],\n",
      "         [0.7301, 0.6276],\n",
      "         [0.7357, 0.0381]],\n",
      "\n",
      "        [[0.7191, 0.4067],\n",
      "         [0.7301, 0.6276],\n",
      "         [0.7357, 0.0381]],\n",
      "\n",
      "        [[0.7191, 0.4067],\n",
      "         [0.7301, 0.6276],\n",
      "         [0.7357, 0.0381]]])\n",
      "tensor([[[0.2138, 0.2138],\n",
      "         [0.5395, 0.5395],\n",
      "         [0.3686, 0.3686]],\n",
      "\n",
      "        [[0.2138, 0.2138],\n",
      "         [0.5395, 0.5395],\n",
      "         [0.3686, 0.3686]],\n",
      "\n",
      "        [[0.2138, 0.2138],\n",
      "         [0.5395, 0.5395],\n",
      "         [0.3686, 0.3686]],\n",
      "\n",
      "        [[0.2138, 0.2138],\n",
      "         [0.5395, 0.5395],\n",
      "         [0.3686, 0.3686]]])\n",
      "tensor([[[0.4007, 0.7220],\n",
      "         [0.4007, 0.7220],\n",
      "         [0.4007, 0.7220]],\n",
      "\n",
      "        [[0.4007, 0.7220],\n",
      "         [0.4007, 0.7220],\n",
      "         [0.4007, 0.7220]],\n",
      "\n",
      "        [[0.4007, 0.7220],\n",
      "         [0.4007, 0.7220],\n",
      "         [0.4007, 0.7220]],\n",
      "\n",
      "        [[0.4007, 0.7220],\n",
      "         [0.4007, 0.7220],\n",
      "         [0.4007, 0.7220]]])\n"
     ]
    }
   ],
   "source": [
    "a =     torch.ones(4, 3, 2)\n",
    "\n",
    "b = a * torch.rand(   3, 2) # 3rd & 2nd dims identical to a, dim 1 absent\n",
    "print(b)\n",
    "\n",
    "c = a * torch.rand(   3, 1) # 3rd dim = 1, 2nd dim identical to a\n",
    "print(c)\n",
    "\n",
    "d = a * torch.rand(   1, 2) # 3rd dim identical to a, 2nd dim = 1\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look closely at the values of each tensor above:\n",
    "\n",
    "The multiplication operation that created b was broadcast over every “layer” of a.\n",
    "\n",
    "For c, the operation was broadcast over every layer and row of a - every 3-element column is identical.\n",
    "\n",
    "For d, we switched it around - now every row is identical, across layers and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell throws a run-time error.This is intentional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2020442815.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[55], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    c = a * torch.rand( , 2, 3)\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(4, 3, 2)\n",
    "\n",
    "b = a * torch.rand(4,3) # dimensions must match last-to-first\n",
    "\n",
    "c = a * torch.rand( , 2, 3)\n",
    "d = a * torch.rand((0, )) # can't broadcast with an empty tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Math with Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch tensors have over three hundred operations that can be performed on them.\n",
    "\n",
    "Here is a small sample from some of the major categories of operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common functions:\n",
      "tensor([[0.6434, 0.4776, 0.4750, 0.6657],\n",
      "        [0.6888, 0.4118, 0.2424, 0.0866]])\n",
      "tensor([[1., -0., 1., 1.],\n",
      "        [1., -0., -0., -0.]])\n",
      "tensor([[ 0., -1.,  0.,  0.],\n",
      "        [ 0., -1., -1., -1.]])\n",
      "tensor([[ 0.5000, -0.4776,  0.4750,  0.5000],\n",
      "        [ 0.5000, -0.4118, -0.2424, -0.0866]])\n",
      "\n",
      "Sine and arcsine:\n",
      "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
      "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
      "tensor([0.0000, 0.7854, 1.5708, 0.7854])\n",
      "\n",
      "Bitwise XOR:\n",
      "tensor([3, 2, 1])\n",
      "\n",
      "Broadcasted, element-wise equality comparison:\n",
      "tensor([[ True, False],\n",
      "        [False, False]])\n",
      "\n",
      "Reduction ops:\n",
      "tensor(4.)\n",
      "4.0\n",
      "tensor(2.5000)\n",
      "tensor(1.2910)\n",
      "tensor(24.)\n",
      "tensor([1, 2])\n",
      "\n",
      "Vectors & Matrices:\n",
      "tensor([ 0.,  0., -1.])\n",
      "tensor([[0.0649, 0.6677],\n",
      "        [0.7826, 0.1332]])\n",
      "tensor([[0.1948, 2.0032],\n",
      "        [2.3478, 0.3995]])\n",
      "torch.return_types.linalg_svd(\n",
      "U=tensor([[-0.4787, -0.8780],\n",
      "        [-0.8780,  0.4787]]),\n",
      "S=tensor([2.5214, 1.8345]),\n",
      "Vh=tensor([[-0.8545, -0.5194],\n",
      "        [ 0.5194, -0.8545]]))\n"
     ]
    }
   ],
   "source": [
    "# common functions\n",
    "a = torch.rand(2, 4) * 2 - 1\n",
    "print('Common functions:')\n",
    "print(torch.abs(a))\n",
    "print(torch.ceil(a))\n",
    "print(torch.floor(a))\n",
    "print(torch.clamp(a, -0.5, 0.5))\n",
    "\n",
    "# trigonometric functions and their inverses\n",
    "angles = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
    "sines = torch.sin(angles)\n",
    "inverses = torch.asin(sines)\n",
    "print('\\nSine and arcsine:')\n",
    "print(angles)\n",
    "print(sines)\n",
    "print(inverses)\n",
    "\n",
    "# bitwise operations\n",
    "print('\\nBitwise XOR:')\n",
    "b = torch.tensor([1, 5, 11])\n",
    "c = torch.tensor([2, 7, 10])\n",
    "print(torch.bitwise_xor(b, c))\n",
    "\n",
    "# comparisons:\n",
    "print('\\nBroadcasted, element-wise equality comparison:')\n",
    "d = torch.tensor([[1., 2.], [3., 4.]])\n",
    "e = torch.ones(1, 2)  # many comparison ops support broadcasting!\n",
    "print(torch.eq(d, e)) # returns a tensor of type bool\n",
    "\n",
    "# reductions:\n",
    "print('\\nReduction ops:')\n",
    "print(torch.max(d))        # returns a single-element tensor\n",
    "print(torch.max(d).item()) # extracts the value from the returned tensor\n",
    "print(torch.mean(d))       # average\n",
    "print(torch.std(d))        # standard deviation\n",
    "print(torch.prod(d))       # product of all numbers\n",
    "print(torch.unique(torch.tensor([1, 2, 1, 2, 1, 2]))) # filter unique elements\n",
    "\n",
    "# vector and linear algebra operations\n",
    "v1 = torch.tensor([1., 0., 0.])         # x unit vector\n",
    "v2 = torch.tensor([0., 1., 0.])         # y unit vector\n",
    "m1 = torch.rand(2, 2)                   # random matrix\n",
    "m2 = torch.tensor([[3., 0.], [0., 3.]]) # three times identity matrix\n",
    "\n",
    "print('\\nVectors & Matrices:')\n",
    "print(torch.linalg.cross(v2, v1)) # negative of z unit vector (v1 x v2 == -v2 x v1)\n",
    "print(m1)\n",
    "m3 = torch.linalg.matmul(m1, m2)\n",
    "print(m3)                  # 3 times m1\n",
    "print(torch.linalg.svd(m3))       # singular value decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Altering Tensors in Place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most binary operations on tensors will return a third, new tensor. When we say c = a * b (where a and b are tensors), the new tensor c will occupy a region of memory distinct from the other tensors.\n",
    "\n",
    "There are times, though, that you may wish to alter a tensor in place - for example, if you’re doing an element-wise computation where you can discard intermediate values. For this, most of the math functions have a version with an appended underscore (_) that will alter a tensor in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
      "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
      "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
      "\n",
      "b:\n",
      "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n",
      "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n",
      "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
    "print('a:')\n",
    "print(a)\n",
    "print(torch.sin(a))   # this operation creates a new tensor in memory\n",
    "print(a)              # a has not changed\n",
    "\n",
    "b = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
    "print('\\nb:')\n",
    "print(b)\n",
    "print(torch.sin_(b))  # note the underscore\n",
    "print(b)              # b has changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For arithmetic operations, there are functions that behave similarly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.0023, 0.4945],\n",
      "        [0.3857, 0.9883]])\n",
      "\n",
      "After adding:\n",
      "tensor([[1.0023, 1.4945],\n",
      "        [1.3857, 1.9883]])\n",
      "tensor([[1.0023, 1.4945],\n",
      "        [1.3857, 1.9883]])\n",
      "tensor([[0.0023, 0.4945],\n",
      "        [0.3857, 0.9883]])\n",
      "\n",
      "After multiplying\n",
      "tensor([[5.1415e-06, 2.4454e-01],\n",
      "        [1.4880e-01, 9.7680e-01]])\n",
      "tensor([[5.1415e-06, 2.4454e-01],\n",
      "        [1.4880e-01, 9.7680e-01]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 2)\n",
    "b = torch.rand(2, 2)\n",
    "\n",
    "print('Before:')\n",
    "print(a)\n",
    "print(b)\n",
    "print('\\nAfter adding:')\n",
    "print(a.add_(b))\n",
    "print(a)\n",
    "print(b)\n",
    "print('\\nAfter multiplying')\n",
    "print(b.mul_(b))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these in-place arithmetic functions are methods on the torch.Tensor object, not attached to the torch module like many other functions (e.g., torch.sin()). As you can see from a.add_(b), the calling tensor is the one that gets changed in place.\n",
    "\n",
    "There is another option for placing the result of a computation in an existing, allocated tensor. Many of the methods and functions we’ve seen so far - including creation methods! - have an out argument that lets you specify a tensor to receive the output. If the out tensor is the correct shape and dtype, this can happen without a new memory allocation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[0.5359, 0.3416],\n",
      "        [0.1129, 0.1823]])\n",
      "tensor([[0.8740, 0.2526],\n",
      "        [0.6923, 0.7545]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 2)\n",
    "b = torch.rand(2, 2)\n",
    "c = torch.zeros(2, 2)\n",
    "old_id = id(c)\n",
    "\n",
    "print(c)\n",
    "d = torch.matmul(a, b, out=c)\n",
    "print(c)                # contents of c have changed\n",
    "\n",
    "assert c is d           # test c & d are same object, not just containing equal values\n",
    "assert id(c) == old_id  # make sure that our new c is the same object as the old one\n",
    "\n",
    "torch.rand(2, 2, out=c) # works for creation too!\n",
    "print(c)                # c has changed again\n",
    "assert id(c) == old_id  # still the same object!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with any object in Python, assigning a tensor to a variable makes the variable a label of the tensor, and does not copy it. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1., 561.],\n",
      "        [  1.,   1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 2)\n",
    "b = a\n",
    "\n",
    "a[0][1] = 561  # we change a...\n",
    "print(b)       # ...and b is also altered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if you want a separate copy of the data to work on? The clone() method is there for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 2)\n",
    "b = a.clone()\n",
    "\n",
    "assert b is not a   # different objects in memory...\n",
    "print(torch.eq(a, b)) # ...but still with the same contents!\n",
    "\n",
    "a[0][1] = 561  # a changes...\n",
    "print(b)       # ...but b is still all ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an important thing to be aware of when using ``clone()``. If your source tensor has autograd, enabled then so will the clone. This will be covered more deeply in the video on autograd, but if you want the light version of the details, continue on.\n",
    "\n",
    "In many cases, this will be what you want. For example, if your model has multiple computation paths in its forward() method, and both the original tensor and its clone contribute to the model’s output, then to enable model learning you want autograd turned on for both tensors. If your source tensor has autograd enabled (which it generally will if it’s a set of learning weights or derived from a computation involving the weights), then you’ll get the result you want.\n",
    "\n",
    "On the other hand, if you’re doing a computation where neither the original tensor nor its clone need to track gradients, then as long as the source tensor has autograd turned off, you’re good to go.\n",
    "\n",
    "There is a third case, though: Imagine you’re performing a computation in your model’s forward() function, where gradients are turned on for everything by default, but you want to pull out some values mid-stream to generate some metrics. In this case, you don’t want the cloned copy of your source tensor to track gradients - performance is improved with autograd’s history tracking turned off. For this, you can use the .detach() method on the source tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7746, 0.2330],\n",
      "        [0.8441, 0.9004]], requires_grad=True)\n",
      "tensor([[0.7746, 0.2330],\n",
      "        [0.8441, 0.9004]], grad_fn=<CloneBackward0>)\n",
      "tensor([[0.7746, 0.2330],\n",
      "        [0.8441, 0.9004]])\n",
      "tensor([[0.7746, 0.2330],\n",
      "        [0.8441, 0.9004]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 2, requires_grad=True) # turn on autograd\n",
    "print(a)\n",
    "\n",
    "b = a.clone()\n",
    "print(b)\n",
    "\n",
    "c = a.detach().clone()\n",
    "print(c)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What’s happening here?\n",
    "\n",
    "We create a with requires_grad=True turned on. We haven’t covered this optional argument yet, but will during the unit on autograd.\n",
    "\n",
    "When we print a, it informs us that the property requires_grad=True - this means that autograd and computation history tracking are turned on.\n",
    "\n",
    "We clone a and label it b. When we print b, we can see that it’s tracking its computation history - it has inherited a’s autograd settings, and added to the computation history.\n",
    "\n",
    "We clone a into c, but we call detach() first.\n",
    "\n",
    "Printing c, we see no computation history, and no requires_grad=True.\n",
    "\n",
    "The detach() method detaches the tensor from its computation history. It says, “do whatever comes next as if autograd was off.” It does this without changing a - you can see that when we print a again at the end, it retains its requires_grad=True property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Fundamentals of Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we’ll create an input tensor full of evenly spaced values on the interval \n",
    "[\n",
    "0\n",
    ",\n",
    "2\n",
    "π\n",
    "]\n",
    "[0,2π], and specify requires_grad=True. (Like most functions that create tensors, torch.linspace() accepts an optional requires_grad option.) Setting this flag means that in every computation that follows, autograd will be accumulating the history of the computation in the output tensors of that computation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.2618, 0.5236, 0.7854, 1.0472, 1.3090, 1.5708, 1.8326, 2.0944,\n",
      "        2.3562, 2.6180, 2.8798, 3.1416, 3.4034, 3.6652, 3.9270, 4.1888, 4.4506,\n",
      "        4.7124, 4.9742, 5.2360, 5.4978, 5.7596, 6.0214, 6.2832],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a = torch.linspace(0., 2. * math.pi, steps=25, requires_grad=True)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll perform a computation, and plot its output in terms of its inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x32b77a930>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = torch.sin(a)\n",
    "plt.plot(a.detach(), b.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look at the tensor b. When we print it, we see an indicator that it is tracking its computation history: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000e+00,  2.5882e-01,  5.0000e-01,  7.0711e-01,  8.6603e-01,\n",
      "         9.6593e-01,  1.0000e+00,  9.6593e-01,  8.6603e-01,  7.0711e-01,\n",
      "         5.0000e-01,  2.5882e-01, -8.7423e-08, -2.5882e-01, -5.0000e-01,\n",
      "        -7.0711e-01, -8.6603e-01, -9.6593e-01, -1.0000e+00, -9.6593e-01,\n",
      "        -8.6603e-01, -7.0711e-01, -5.0000e-01, -2.5882e-01,  1.7485e-07],\n",
      "       grad_fn=<SinBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This grad_fn gives us a hint that when we execute the backpropagation step and compute gradients, we’ll need to compute the derivative of \n",
    "sin\n",
    "⁡\n",
    "(\n",
    "x\n",
    ")\n",
    "sin(x) for all this tensor’s inputs.\n",
    "\n",
    "Let’s perform some more computations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000e+00,  5.1764e-01,  1.0000e+00,  1.4142e+00,  1.7321e+00,\n",
      "         1.9319e+00,  2.0000e+00,  1.9319e+00,  1.7321e+00,  1.4142e+00,\n",
      "         1.0000e+00,  5.1764e-01, -1.7485e-07, -5.1764e-01, -1.0000e+00,\n",
      "        -1.4142e+00, -1.7321e+00, -1.9319e+00, -2.0000e+00, -1.9319e+00,\n",
      "        -1.7321e+00, -1.4142e+00, -1.0000e+00, -5.1764e-01,  3.4969e-07],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([ 1.0000e+00,  1.5176e+00,  2.0000e+00,  2.4142e+00,  2.7321e+00,\n",
      "         2.9319e+00,  3.0000e+00,  2.9319e+00,  2.7321e+00,  2.4142e+00,\n",
      "         2.0000e+00,  1.5176e+00,  1.0000e+00,  4.8236e-01, -3.5763e-07,\n",
      "        -4.1421e-01, -7.3205e-01, -9.3185e-01, -1.0000e+00, -9.3185e-01,\n",
      "        -7.3205e-01, -4.1421e-01,  4.7684e-07,  4.8236e-01,  1.0000e+00],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "c = 2 * b\n",
    "print(c)\n",
    "\n",
    "d = c + 1\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let’s compute a single-element output. When you call .backward() on a tensor with no arguments, it expects the calling tensor to contain only a single element, as is the case when computing a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(25., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = d.sum()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each grad_fn stored with our tensors allows you to walk the computation all the way back to its inputs with its next_functions property. We can see below that drilling down on this property on d shows us the gradient functions for all the prior tensors. Note that a.grad_fn is reported as None, indicating that this was an input to the function with no history of its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\n",
      "<AddBackward0 object at 0x32e0cf970>\n",
      "((<MulBackward0 object at 0x32e0ccdf0>, 0), (None, 0))\n",
      "((<SinBackward0 object at 0x32e0ccdf0>, 0), (None, 0))\n",
      "((<AccumulateGrad object at 0x32e0cf970>, 0),)\n",
      "()\n",
      "\n",
      "c:\n",
      "<MulBackward0 object at 0x32e0ccdf0>\n",
      "\n",
      "b:\n",
      "<SinBackward0 object at 0x32e0ccdf0>\n",
      "\n",
      "a:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('d:')\n",
    "print(d.grad_fn)\n",
    "print(d.grad_fn.next_functions)\n",
    "print(d.grad_fn.next_functions[0][0].next_functions)\n",
    "print(d.grad_fn.next_functions[0][0].next_functions[0][0].next_functions)\n",
    "print(d.grad_fn.next_functions[0][0].next_functions[0][0].next_functions[0][0].next_functions)\n",
    "print('\\nc:')\n",
    "print(c.grad_fn)\n",
    "print('\\nb:')\n",
    "print(b.grad_fn)\n",
    "print('\\na:')\n",
    "print(a.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all this machinery in place, how do we get derivatives out? You call the backward() method on the output, and check the input’s grad property to inspect the gradients:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.0000e+00,  1.9319e+00,  1.7321e+00,  1.4142e+00,  1.0000e+00,\n",
      "         5.1764e-01, -8.7423e-08, -5.1764e-01, -1.0000e+00, -1.4142e+00,\n",
      "        -1.7321e+00, -1.9319e+00, -2.0000e+00, -1.9319e+00, -1.7321e+00,\n",
      "        -1.4142e+00, -1.0000e+00, -5.1764e-01,  2.3850e-08,  5.1764e-01,\n",
      "         1.0000e+00,  1.4142e+00,  1.7321e+00,  1.9319e+00,  2.0000e+00])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x32e0cd0a0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out.backward()\n",
    "print(a.grad)\n",
    "plt.plot(a.detach(), a.grad.detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the computations steps we took to get here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.linspace(0., 2. * math.pi, steps=25, requires_grad=True)\n",
    "b = torch.sin(a)\n",
    "c = 2 * b\n",
    "d = c + 1\n",
    "out = d.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a constant, as we did to compute d, does not change the derivative. That leaves c = 2 * b = 2 * sin(a), the derivative of which should be 2 * cos(a). Looking at the graph above, that's just what we see.\n",
    "\n",
    "Be aware that only leaf nodes of the computation have their gradients computed. If you tried, for example , print(c.grad) you'd get back None. In this simple example, only the input is a leaf node, so only it has gradients computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd in Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve had a brief look at how autograd works, but how does it look when it’s used for its intended purpose? Let’s define a small model and examine how it changes after a single training batch. First, define a few constants, our model, and some stand-ins for inputs and outputs:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "DIM_IN = 1000\n",
    "HIDDEN_SIZE = 100\n",
    "DIM_OUT = 10\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.layer1 = torch.nn.Linear(DIM_IN, HIDDEN_SIZE)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.layer2 = torch.nn.Linear(HIDDEN_SIZE, DIM_OUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "some_input = torch.randn(BATCH_SIZE, DIM_IN, requires_grad=False)\n",
    "ideal_output = torch.randn(BATCH_SIZE, DIM_OUT, requires_grad=False)\n",
    "\n",
    "model = TinyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing you might notice is that we never specify requires_grad=True for the model’s layers. Within a subclass of torch.nn.Module, it’s assumed that we want to track gradients on the layers’ weights for learning.\n",
    "\n",
    "If we look at the layers of the model, we can examine the values of the weights, and verify that no gradients have been computed yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0239,  0.0084, -0.0608,  0.0937, -0.0914,  0.0711,  0.0752,  0.0715,\n",
      "        -0.0112, -0.0483], grad_fn=<SliceBackward0>)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.layer2.weight[0][0:10]) # just a small slice\n",
    "print(model.layer2.weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see how this changes when we run through one training batch. For a loss function, we’ll just use the square of the Euclidean distance between our prediction and the ideal_output, and we’ll use a basic stochastic gradient descent optimizer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(153.8024, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "prediction = model(some_input)\n",
    "\n",
    "loss = (ideal_output - prediction).pow(2).sum()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's call loss.backward() and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0239,  0.0084, -0.0608,  0.0937, -0.0914,  0.0711,  0.0752,  0.0715,\n",
      "        -0.0112, -0.0483], grad_fn=<SliceBackward0>)\n",
      "tensor([  0.8154,  -1.4623,  -4.0893,  -2.8619,  -0.3795, -10.1996,   4.3187,\n",
      "         -1.0485,  -4.7910,   0.3056])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(model.layer2.weight[0][0:10])\n",
    "print(model.layer2.weight.grad[0][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the gradients have been computed for each learning weight, but the weights remain unchanged, because we haven’t run the optimizer yet. The optimizer is responsible for updating model weights based on the computed gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0247,  0.0099, -0.0567,  0.0966, -0.0910,  0.0813,  0.0709,  0.0725,\n",
      "        -0.0064, -0.0486], grad_fn=<SliceBackward0>)\n",
      "tensor([  0.8154,  -1.4623,  -4.0893,  -2.8619,  -0.3795, -10.1996,   4.3187,\n",
      "         -1.0485,  -4.7910,   0.3056])\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()\n",
    "print(model.layer2.weight[0][0:10])\n",
    "print(model.layer2.weight.grad[0][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that layer2's weights have changed.\n",
    "\n",
    "One important thing about the process: After calling optimizer.step(), you need to call optimzer.zero_grad(), or else every time you run loss.backward(),the gradients on the learning weights will accumulate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0.8154,  -1.4623,  -4.0893,  -2.8619,  -0.3795, -10.1996,   4.3187,\n",
      "         -1.0485,  -4.7910,   0.3056])\n",
      "tensor([  1.8563,  -7.4775,  -8.3095, -15.9044,  15.7750, -47.1272,  21.3480,\n",
      "         -7.5263, -24.6556,   1.0563])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(model.layer2.weight.grad[0][0:10])\n",
    "\n",
    "for i in range(0, 5):\n",
    "    prediction = model(some_input)\n",
    "    loss = (ideal_output - prediction).pow(2).sum()\n",
    "    loss.backward()\n",
    "\n",
    "print(model.layer2.weight.grad[0][0:10])\n",
    "\n",
    "optimizer.zero_grad(set_to_none=False)\n",
    "\n",
    "print(model.layer2.weight.grad[0][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the cell above, you should see that after running loss.backward() multiple times, the magnitudes of most of the gradients will be much larger. Failing to zero the gradients before running your next training batch will cause the gradients to blow up in this manner, causing incorrect and unpredictable learning results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning Autograd Off and On"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are situations where you will need fine-grained control over whether autograd is enabled. There are multiple ways to do this, depending on the situation.\n",
    "\n",
    "The simplest is to change the requires_grad flag on a tensor directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], requires_grad=True)\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]], grad_fn=<MulBackward0>)\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 3, requires_grad=True)\n",
    "print(a)\n",
    "\n",
    "b1 = 2 * a\n",
    "print(b1)\n",
    "\n",
    "a.requires_grad = False\n",
    "b2 = 2 * a\n",
    "print(b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, we see that b1 has a grad_fn (i.e., a traced computation history), which is what we expect, since it was derived from a tensor, a, that had autograd turned on. When we turn off autograd explicitly with a.requires_grad = False, computation history is no longer tracked, as we see when we compute b2.\n",
    "\n",
    "If you only need autograd turned off temporarily, a better way is to use the torch.no_grad():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]], grad_fn=<AddBackward0>)\n",
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n",
      "tensor([[6., 6., 6.],\n",
      "        [6., 6., 6.]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 3, requires_grad=True) * 2\n",
    "b = torch.ones(2, 3, requires_grad=True) * 3\n",
    "\n",
    "c1 = a + b\n",
    "print(c1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    c2 = a + b\n",
    "\n",
    "print(c2)\n",
    "\n",
    "c3 = a * b\n",
    "print(c3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.no_grad() can also be used as a function or method decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]], grad_fn=<AddBackward0>)\n",
      "tensor([[5., 5., 5.],\n",
      "        [5., 5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "def add_tensors1(x, y):\n",
    "    return x + y\n",
    "\n",
    "@torch.no_grad()\n",
    "def add_tensors2(x, y):\n",
    "    return x + y\n",
    "\n",
    "\n",
    "a = torch.ones(2, 3, requires_grad=True) * 2\n",
    "b = torch.ones(2, 3, requires_grad=True) * 3\n",
    "\n",
    "c1 = add_tensors1(a, b)\n",
    "print(c1)\n",
    "\n",
    "c2 = add_tensors2(a, b)\n",
    "print(c2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There’s a corresponding context manager, torch.enable_grad(), for turning autograd on when it isn’t already. It may also be used as a decorator.\n",
    "\n",
    "Finally, you may have a tensor that requires gradient tracking, but you want a copy that does not. For this we have the Tensor object’s detach() method - it creates a copy of the tensor that is detached from the computation history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4511, 0.0385, 0.8225, 0.4769, 0.6865], requires_grad=True)\n",
      "tensor([0.4511, 0.0385, 0.8225, 0.4769, 0.6865])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, requires_grad=True)\n",
    "y = x.detach()\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Models with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.nn.Module and torch.nn.Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important behavior of torch.nn.Module is registering parameters. If a particular Module subclass has learning weights, these weights are expressed as instances of torch.nn.Parameter. The Parameter class is a subclass of torch.Tensor, with the special behavior that when they are assigned as attributes of a Module, they are added to the list of that modules parameters. These parameters may be accessed through the parameters() method on the Module class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a simple example, here’s a very simple model with two linear layers and an activation function. We’ll create an instance of it and ask it to report on its parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "Just one layer:\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      "Model params:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0269, -0.0572,  0.0371,  ..., -0.0579,  0.0048, -0.0493],\n",
      "        [ 0.0512,  0.0596,  0.0321,  ...,  0.0242, -0.0196, -0.0885],\n",
      "        [ 0.0633, -0.0711, -0.0552,  ...,  0.0622, -0.0284,  0.0644],\n",
      "        ...,\n",
      "        [ 0.0781,  0.0191, -0.0212,  ...,  0.0927, -0.0799,  0.0668],\n",
      "        [-0.0997, -0.0837, -0.0199,  ..., -0.0828, -0.0227, -0.0799],\n",
      "        [-0.0459,  0.0956, -0.0462,  ..., -0.0242, -0.0137, -0.0730]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0004, -0.0948,  0.0976, -0.0266, -0.0109, -0.0458,  0.0133, -0.0498,\n",
      "         0.0078, -0.0184,  0.0256, -0.0189, -0.0244, -0.0322, -0.0227, -0.0082,\n",
      "         0.0374,  0.0592, -0.0335, -0.0576, -0.0127,  0.0529,  0.0972,  0.0163,\n",
      "         0.0393,  0.0612, -0.0722,  0.0747,  0.0914, -0.0530, -0.0989, -0.0997,\n",
      "         0.0363,  0.0426,  0.0416,  0.0179, -0.0708, -0.0531,  0.0300, -0.0692,\n",
      "         0.0234,  0.0206,  0.0367, -0.0621,  0.0625,  0.0708,  0.0653, -0.0397,\n",
      "        -0.0793,  0.0432, -0.0329,  0.0776,  0.0824, -0.0410, -0.0527, -0.0523,\n",
      "        -0.0538,  0.0673,  0.0903,  0.0031, -0.0350,  0.0270, -0.0895,  0.0510,\n",
      "         0.0929,  0.0011,  0.0985,  0.0326,  0.0730, -0.0993,  0.0729, -0.0930,\n",
      "         0.0475,  0.0555, -0.0413, -0.0548, -0.0191,  0.0333,  0.0627,  0.0902,\n",
      "         0.0053, -0.0645,  0.0305,  0.0669, -0.0748,  0.0199, -0.0652,  0.0233,\n",
      "         0.0465, -0.0059, -0.0487,  0.0281, -0.0402, -0.0360,  0.0301, -0.0716,\n",
      "        -0.0010, -0.0073, -0.0898,  0.0604, -0.0737, -0.0805,  0.0458, -0.0976,\n",
      "         0.0571,  0.0183,  0.0472, -0.0350,  0.0334,  0.0308,  0.0240,  0.0581,\n",
      "        -0.0050, -0.0116, -0.0093,  0.0203, -0.0815, -0.0631, -0.0896, -0.0882,\n",
      "         0.0279,  0.0026,  0.0126, -0.0223, -0.0086, -0.0430,  0.0466,  0.0222,\n",
      "         0.0542,  0.0645, -0.0006, -0.0916, -0.0852,  0.0038,  0.0262, -0.0339,\n",
      "        -0.0639,  0.0656,  0.0836,  0.0573,  0.0187,  0.0745,  0.0966,  0.0603,\n",
      "        -0.0746, -0.0064, -0.0116,  0.0420, -0.0144, -0.0194,  0.0667,  0.0432,\n",
      "        -0.0256, -0.0240,  0.0486,  0.0294,  0.0526, -0.0890,  0.0945, -0.0654,\n",
      "        -0.0980,  0.0481,  0.0682, -0.0970, -0.0119, -0.0946,  0.0641,  0.0644,\n",
      "         0.0173, -0.0089,  0.0547,  0.0184, -0.0070,  0.0871, -0.0808,  0.0703,\n",
      "         0.0516, -0.0843, -0.0165, -0.0988, -0.0446,  0.0970, -0.0041,  0.0283,\n",
      "        -0.0307, -0.0155,  0.0617, -0.0667,  0.0161,  0.0790,  0.0561,  0.0376,\n",
      "        -0.0861,  0.0203,  0.0435,  0.0942,  0.0600, -0.0524,  0.0371, -0.0493],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0186,  0.0256,  0.0118,  ..., -0.0202, -0.0020,  0.0262],\n",
      "        [-0.0680,  0.0146,  0.0158,  ...,  0.0673,  0.0675,  0.0271],\n",
      "        [ 0.0362,  0.0602,  0.0296,  ...,  0.0140, -0.0139,  0.0343],\n",
      "        ...,\n",
      "        [-0.0170,  0.0220,  0.0508,  ...,  0.0182, -0.0060, -0.0042],\n",
      "        [-0.0218, -0.0280,  0.0579,  ..., -0.0669,  0.0103, -0.0374],\n",
      "        [ 0.0642,  0.0509,  0.0302,  ...,  0.0090, -0.0527,  0.0187]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0644,  0.0209,  0.0613,  0.0080,  0.0295, -0.0696, -0.0442,  0.0195,\n",
      "        -0.0544,  0.0702], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer params:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0186,  0.0256,  0.0118,  ..., -0.0202, -0.0020,  0.0262],\n",
      "        [-0.0680,  0.0146,  0.0158,  ...,  0.0673,  0.0675,  0.0271],\n",
      "        [ 0.0362,  0.0602,  0.0296,  ...,  0.0140, -0.0139,  0.0343],\n",
      "        ...,\n",
      "        [-0.0170,  0.0220,  0.0508,  ...,  0.0182, -0.0060, -0.0042],\n",
      "        [-0.0218, -0.0280,  0.0579,  ..., -0.0669,  0.0103, -0.0374],\n",
      "        [ 0.0642,  0.0509,  0.0302,  ...,  0.0090, -0.0527,  0.0187]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0644,  0.0209,  0.0613,  0.0080,  0.0295, -0.0696, -0.0442,  0.0195,\n",
      "        -0.0544,  0.0702], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "\n",
    "print('The model:')\n",
    "print(tinymodel)\n",
    "\n",
    "print('\\n\\nJust one layer:')\n",
    "print(tinymodel.linear2)\n",
    "\n",
    "print('\\n\\nModel params:')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('\\n\\nLayer params:')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the fundamental structure of a PyTorch model: there is an __init__() method that defines the layers and other components of a model, and a forward() method where the computation gets done. Note that we can print the model, or any of its submodules, to learn about its structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Layer Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic type of neural network layer is a linear or fully connected layer. This is a layer where every input influences every output of the layer to a degree specified by the layer’s weights. If a model has m inputs and n outputs, the weights will be an m x n matrix. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[0.2240, 0.8502, 0.0382]])\n",
      "\n",
      "\n",
      "Weight and Bias parameters:\n",
      "Parameter containing:\n",
      "tensor([[0.4565, 0.4714, 0.2435],\n",
      "        [0.4783, 0.2244, 0.3859]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1042, -0.2300], requires_grad=True)\n",
      "\n",
      "\n",
      "Output:\n",
      "tensor([[0.6165, 0.0826]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lin = torch.nn.Linear(3, 2)\n",
    "x = torch.rand(1, 3)\n",
    "print('Input:')\n",
    "print(x)\n",
    "\n",
    "print('\\n\\nWeight and Bias parameters:')\n",
    "for param in lin.parameters():\n",
    "    print(param)\n",
    "\n",
    "y = lin(x)\n",
    "print('\\n\\nOutput:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do the matrix multiplication of x by the linear layer’s weights, and add the biases, you’ll find that you get the output vector y.\n",
    "\n",
    "One other important feature to note: When we checked the weights of our layer with lin.weight, it reported itself as a Parameter (which is a subclass of Tensor), and let us know that it’s tracking gradients with autograd. This is a default behavior for Parameter that differs from Tensor.\n",
    "\n",
    "Linear layers are used widely in deep learning models. One of the most common places you’ll see them is in classifier models, which will usually have one or more linear layers at the end, where the last layer will have n outputs, where n is the number of classes the classifier addresses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional layers are built to handle data with a high degree of spatial correlation. They are very commonly used in computer vision, where they detect close groupings of features which the compose into higher-level features. They pop up in other contexts too - for example, in NLP applications, where a word’s immediate context (that is, the other words nearby in the sequence) can affect the meaning of a sentence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "\n",
    "\n",
    "class LeNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = torch.nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s break down what’s happening in the convolutional layers of this model. Starting with conv1:\n",
    "\n",
    "LeNet5 is meant to take in a 1x32x32 black & white image. The first argument to a convolutional layer’s constructor is the number of input channels. Here, it is 1. If we were building this model to look at 3-color channels, it would be 3.\n",
    "\n",
    "A convolutional layer is like a window that scans over the image, looking for a pattern it recognizes. These patterns are called features, and one of the parameters of a convolutional layer is the number of features we would like it to learn. This is the second argument to the constructor is the number of output features. Here, we’re asking our layer to learn 6 features.\n",
    "\n",
    "Just above, I likened the convolutional layer to a window - but how big is the window? The third argument is the window or kernel size. Here, the “5” means we’ve chosen a 5x5 kernel. (If you want a kernel with height different from width, you can specify a tuple for this argument - e.g., (3, 5) to get a 3x5 convolution kernel.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of a convolutional layer is an activation map - a spatial representation of the presence of features in the input tensor. conv1 will give us an output tensor of 6x28x28; 6 is the number of features, and 28 is the height and width of our map. (The 28 comes from the fact that when scanning a 5-pixel window over a 32-pixel row, there are only 28 valid positions.)\n",
    "\n",
    "We then pass the output of the convolution through a ReLU activation function (more on activation functions later), then through a max pooling layer. The max pooling layer takes features near each other in the activation map and groups them together. It does this by reducing the tensor, merging every 2x2 group of cells in the output into a single cell, and assigning that cell the maximum value of the 4 cells that went into it. This gives us a lower-resolution version of the activation map, with dimensions 6x14x14.\n",
    "\n",
    "Our next convolutional layer, conv2, expects 6 input channels (corresponding to the 6 features sought by the first layer), has 16 output channels, and a 3x3 kernel. It puts out a 16x12x12 activation map, which is again reduced by a max pooling layer to 16x6x6. Prior to passing this output to the linear layers, it is reshaped to a 16 * 6 * 6 = 576-element vector for consumption by the next layer.\n",
    "\n",
    "There are convolutional layers for addressing 1D, 2D, and 3D tensors. There are also many more optional arguments for a conv layer constructor, including stride length(e.g., only scanning every second or every third position) in the input, padding (so you can scan out to the edges of the input), and more. See the documentation for more information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent neural networks (or RNNs) are used for sequential data - anything from time-series measurements from a scientific instrument to natural language sentences to DNA nucleotides. An RNN does this by maintaining a hidden state that acts as a sort of memory for what it has seen in the sequence so far.\n",
    "\n",
    "The internal structure of an RNN layer - or its variants, the LSTM (long short-term memory) and GRU (gated recurrent unit) - is moderately complex and beyond the scope of this video, but we’ll show you what one looks like in action with an LSTM-based part-of-speech tagger (a type of classifier that tells you if a word is a noun, verb, etc.):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor has four arguments:\n",
    "\n",
    "vocab_size is the number of words in the input vocabulary. Each word is a one-hot vector (or unit vector) in a vocab_size-dimensional space.\n",
    "\n",
    "tagset_size is the number of tags in the output set.\n",
    "\n",
    "embedding_dim is the size of the embedding space for the vocabulary. An embedding maps a vocabulary onto a low-dimensional space, where words with similar meanings are close together in the space.\n",
    "\n",
    "hidden_dim is the size of the LSTM’s memory.\n",
    "\n",
    "The input will be a sentence with the words represented as indices of one-hot vectors. The embedding layer will then map these down to an embedding_dim-dimensional space. The LSTM takes this sequence of embeddings and iterates over it, fielding an output vector of length hidden_dim. The final linear layer acts as a classifier; applying log_softmax() to the output of the final layer converts the output into a normalized set of estimated probabilities that a given word maps to a given tag.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers are multi-purpose networks that have taken over the state of the art in NLP with models like BERT. A discussion of transformer architecture is beyond the scope of this video, but PyTorch has a Transformer class that allows you to define the overall parameters of a transformer model - the number of attention heads, the number of encoder & decoder layers, dropout and activation functions, etc. (You can even build the BERT model from this single class, with the right parameters!) The torch.nn.Transformer class also has classes to encapsulate the individual components (TransformerEncoder, TransformerDecoder) and subcomponents (TransformerEncoderLayer, TransformerDecoderLayer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Layers and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Manipulation Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other layer types that perform important functions in models, but don’t participate in the learning process themselves.\n",
    "\n",
    "Max pooling (and its twin, min pooling) reduce a tensor by combining cells, and assigning the maximum value of the input cells to the output cell (we saw this). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3224, 0.3377, 0.6741, 0.1029, 0.4638, 0.4790],\n",
      "         [0.2881, 0.5509, 0.2951, 0.4853, 0.7459, 0.7176],\n",
      "         [0.1691, 0.4626, 0.7202, 0.0369, 0.5813, 0.1516],\n",
      "         [0.2189, 0.5179, 0.0519, 0.0983, 0.5620, 0.2256],\n",
      "         [0.9773, 0.4204, 0.2714, 0.3087, 0.7568, 0.6110],\n",
      "         [0.4765, 0.8580, 0.8190, 0.9481, 0.5266, 0.3538]]])\n",
      "tensor([[[0.7202, 0.7459],\n",
      "         [0.9773, 0.9481]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 6, 6)\n",
    "print(my_tensor)\n",
    "\n",
    "maxpool_layer = torch.nn.MaxPool2d(3)\n",
    "print(maxpool_layer(my_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look closely at the values above, you’ll see that each of the values in the maxpooled output is the maximum value of each quadrant of the 6x6 input.\n",
    "\n",
    "Normalization layers re-center and normalize the output of one layer before feeding it to another. Centering and scaling the intermediate tensors has a number of beneficial effects, such as letting you use higher learning rates without exploding/vanishing gradients.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[19.5715, 12.8166, 19.7759, 21.2435],\n",
      "         [ 8.5956, 19.6041, 12.2709,  7.7482],\n",
      "         [ 7.8302, 16.3638, 17.3497, 16.2224],\n",
      "         [15.9994, 18.0637, 24.4571, 17.9766]]])\n",
      "tensor(15.9931)\n",
      "tensor([[[ 0.3741, -1.6978,  0.4368,  0.8869],\n",
      "         [-0.7394,  1.6137,  0.0462, -0.9205],\n",
      "         [-1.7209,  0.5004,  0.7570,  0.4636],\n",
      "         [-0.9803, -0.3327,  1.6730, -0.3600]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "tensor(8.1956e-08, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 4, 4) * 20 + 5\n",
    "print(my_tensor)\n",
    "\n",
    "print(my_tensor.mean())\n",
    "\n",
    "norm_layer = torch.nn.BatchNorm1d(4)\n",
    "normed_tensor = norm_layer(my_tensor)\n",
    "print(normed_tensor)\n",
    "\n",
    "print(normed_tensor.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the cell above, we’ve added a large scaling factor and offset to an input tensor; you should see the input tensor’s mean() somewhere in the neighborhood of 15. After running it through the normalization layer, you can see that the values are smaller, and grouped around zero - in fact, the mean should be very small (> 1e-8).\n",
    "\n",
    "This is beneficial because many activation functions (discussed below) have their strongest gradients near 0, but sometimes suffer from vanishing or exploding gradients for inputs that drive them far away from zero. Keeping the data centered around the area of steepest gradient will tend to mean faster, better learning and higher feasible learning rates.\n",
    "\n",
    "Dropout layers are a tool for encouraging sparse representations in your model - that is, pushing it to do inference with less data.\n",
    "\n",
    "Dropout layers work by randomly setting parts of the input tensor during training - dropout layers are always turned off for inference. This forces the model to learn against this masked or reduced dataset. For example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.1841, 0.0000],\n",
      "         [1.2755, 0.0000, 1.0831, 0.0000],\n",
      "         [0.8027, 0.5163, 0.3240, 0.0000],\n",
      "         [0.0000, 0.5399, 0.0000, 0.8007]]])\n",
      "tensor([[[0.0000, 0.0000, 0.1841, 0.5716],\n",
      "         [1.2755, 0.0000, 1.0831, 0.0000],\n",
      "         [0.8027, 0.0000, 0.3240, 0.4346],\n",
      "         [0.0000, 0.5399, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 4, 4)\n",
    "\n",
    "dropout = torch.nn.Dropout(p=0.4)\n",
    "print(dropout(my_tensor))\n",
    "print(dropout(my_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, you can see the effect of dropout on a sample tensor. You can use the optional p argument to set the probability of an individual weight dropping out; if you don’t it defaults to 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation functions make deep learning possible. A neural network is really a program - with many parameters - that simulates a mathematical function. If all we did was multiple tensors by layer weights repeatedly, we could only simulate linear functions; further, there would be no point to having many layers, as the whole network would reduce could be reduced to a single matrix multiplication. Inserting non-linear activation functions between layers is what allows a deep learning model to simulate any function, rather than just linear ones.\n",
    "\n",
    "torch.nn.Module has objects encapsulating all of the major activation functions including ReLU and its many variants, Tanh, Hardtanh, sigmoid, and more. It also includes other functions, such as Softmax, that are most useful at the output stage of a model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss functions tell us how far a model’s prediction is from the correct answer. PyTorch contains a variety of loss functions, including common MSE (mean squared error = L2 norm), Cross Entropy Loss and Negative Likelihood Loss (useful for classifiers), and others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch TensorBoard Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before You Start\n",
    "To run this tutorial, you’ll need to install PyTorch, TorchVision, Matplotlib, and TensorBoard.\n",
    "\n",
    "With conda:\n",
    "conda install pytorch torchvision -c pytorch\n",
    "conda install matplotlib tensorboard\n",
    "\n",
    "With pip:\n",
    "pip install torch torchvision matplotlib tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we’ll be training a variant of LeNet-5 against the Fashion-MNIST dataset. Fashion-MNIST is a set of image tiles depicting various garments, with ten class labels indicating the type of garment depicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch model and training necessities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Image datasets and image manipulation\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Image display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# In case you are using an environment that has TensorFlow installed,\n",
    "# such as Google Colab, uncomment the following code to avoid\n",
    "# a bug with saving embeddings to your TensorBoard directory\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import tensorboard as tb\n",
    "# tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing Images in TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by adding sample images from our dataset to TensorBoard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gather datasets and prepare them for consumption\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Store separate training and validations splits in ./data\n",
    "training_set = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_set,\n",
    "                                              batch_size=4,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=2)\n",
    "\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set,\n",
    "                                                batch_size=4,\n",
    "                                                shuffle=False,\n",
    "                                                num_workers=2)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# Extract a batch of 4 images\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we used TorchVision and Matplotlib to create a visual grid of a minibatch of our input data. Below, we use the add_image() call on SummaryWriter to log the image for consumption by TensorBoard, and we also call flush() to make sure it’s written to disk right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default log_dir argument is \"runs\" - but it's good to be specific\n",
    "# torch.utils.tensorboard.SummaryWriter is imported above\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n",
    "\n",
    "# Write image data to TensorBoard log dir\n",
    "writer.add_image('Four Fashion-MNIST Images', img_grid)\n",
    "writer.flush()\n",
    "\n",
    "# To view, start TensorBoard on the command line with:\n",
    "#   tensorboard --logdir=runs\n",
    "# ...and open a browser tab to http://localhost:6006/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you start TensorBoard at the command line and open it in a new browser tab (usually at localhost:6006), you should see the image grid under the IMAGES tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing scalars to Visualize Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard is useful for tracking the progress and efficacy of your training. Below, we’ll run a training loop, track some metrics, and save the data for TensorBoard’s consumption.\n",
    "\n",
    "Let’s define a model to categorize our image tiles, and an optimizer and loss function for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a single epocg, and evaluate the training vs. validation set losses every 1000 batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "Batch 1000\n",
      "Batch 2000\n",
      "Batch 3000\n",
      "Batch 4000\n",
      "Batch 5000\n",
      "Batch 6000\n",
      "Batch 7000\n",
      "Batch 8000\n",
      "Batch 9000\n",
      "Batch 10000\n",
      "Batch 11000\n",
      "Batch 12000\n",
      "Batch 13000\n",
      "Batch 14000\n",
      "Batch 15000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "print(len(validation_loader))\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(training_loader, 0):\n",
    "        # basic training loop\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # Every 1000 mini-batches...\n",
    "            print('Batch {}'.format(i + 1))\n",
    "            # Check against the validation set\n",
    "            running_vloss = 0.0\n",
    "\n",
    "            # In evaluation mode some model specific operations can be omitted eg. dropout layer\n",
    "            net.train(False) # Switching to evaluation mode, eg. turning off regularisation\n",
    "            for j, vdata in enumerate(validation_loader, 0):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = net(vinputs)\n",
    "                vloss = criterion(voutputs, vlabels)\n",
    "                running_vloss += vloss.item()\n",
    "            net.train(True) # Switching back to training mode, eg. turning on regularisation\n",
    "\n",
    "            avg_loss = running_loss / 1000\n",
    "            avg_vloss = running_vloss / len(validation_loader)\n",
    "\n",
    "            # Log the running loss averaged per batch\n",
    "            writer.add_scalars('Training vs. Validation Loss',\n",
    "                            { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                            epoch * len(training_loader) + i)\n",
    "\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "switch to your open TensorBoard and have a look at the SCALARS tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard can also be used to examine the data flow within your model. To do this, call the add_graph() method with a model and sample input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, grab a single mini-batch of images\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# add_graph() will trace the sample input through your model,\n",
    "# and render it as a graph.\n",
    "writer.add_graph(net, images)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you switch over to TensorBoard, you should see a GRAPHS tab. Double-click the “NET” node to see the layers and data flow within your model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Your Dataset With Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 28-by-28 image tiles we’re using can be modeled as 784-dimensional vectors (28 * 28 = 784). It can be instructive to project this to a lower-dimensional representation. The add_embedding() method will project a set of data onto the three dimensions with highest variance, and display them as an interactive 3D chart. The add_embedding() method does this automatically by projecting to the three dimensions with highest variance.\n",
    "\n",
    "Below, we’ll take a sample of our data, and generate such an embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random subset of data and corresponding labels\n",
    "def select_n_random(data, labels, n=100):\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# Extract a random subset of data\n",
    "images, labels = select_n_random(training_set.data, training_set.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[label] for label in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if you switch to TensorBoard and select the PROJECTOR tab, you should see a 3D representation of the projection. You can rotate and zoom the model. Examine it at large and small scales, and see whether you can spot patterns in the projected data and the clustering of labels.\n",
    "\n",
    "For better visibility, it’s recommended to:\n",
    "\n",
    "Select “label” from the “Color by” drop-down on the left.\n",
    "\n",
    "Toggle the Night Mode icon along the top to place the light-colored images on a dark background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we’ve discussed and demonstrated:\n",
    "\n",
    "Building models with the neural network layers and functions of the torch.nn module\n",
    "\n",
    "The mechanics of automated gradient computation, which is central to gradient-based model training\n",
    "\n",
    "Using TensorBoard to visualize training progress and other activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we’ll be adding some new tools to your inventory:\n",
    "\n",
    "We’ll get familiar with the dataset and dataloader abstractions, and how they ease the process of feeding data to your model during a training loop\n",
    "\n",
    "We’ll discuss specific loss functions and when to use them\n",
    "\n",
    "We’ll look at PyTorch optimizers, which implement algorithms to adjust model weights based on the outcome of a loss function\n",
    "\n",
    "Finally, we’ll pull all of these together and see a full PyTorch training loop in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataset and DataLoader classes encapsulate the process of pulling your data from storage and exposing it to your training loop in batches.\n",
    "\n",
    "The Dataset is responsible for accessing and processing single instances of data.\n",
    "\n",
    "The DataLoader pulls instances of data from the Dataset (either automatically or with a sampler that you define), collects them in batches, and returns them for consumption by your training loop. The DataLoader works with all kinds of datasets, regardless of the type of data they contain.\n",
    "\n",
    "For this tutorial, we’ll be using the Fashion-MNIST dataset provided by TorchVision. We use torchvision.transforms.Normalize() to zero-center and normalize the distribution of the image tile content, and download both training and validation data splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as always, let's visualize the data as a sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ankle Boot  Dress  Sneaker  Pullover\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model\n",
    "The model we'll use in this example is a variant of LeNet-5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = GarmentClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we’ll be using a cross-entropy loss. For demonstration purposes, we’ll create batches of dummy output and label values, run them through the loss function, and examine the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1966, 0.7977, 0.5737, 0.1013, 0.7882, 0.1922, 0.6714, 0.8853, 0.9169,\n",
      "         0.1052],\n",
      "        [0.9903, 0.7030, 0.2487, 0.7148, 0.5824, 0.1114, 0.8666, 0.7997, 0.7809,\n",
      "         0.2232],\n",
      "        [0.9658, 0.6763, 0.4772, 0.7458, 0.1240, 0.7907, 0.8089, 0.8651, 0.5805,\n",
      "         0.5930],\n",
      "        [0.0895, 0.6302, 0.5365, 0.2451, 0.5431, 0.5948, 0.9977, 0.2078, 0.6073,\n",
      "         0.2784]])\n",
      "tensor([1, 5, 3, 7])\n",
      "Total loss for this batch: 2.4384467601776123\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# NB: Loss functions expect data in batches, so we're creating batches of 4\n",
    "# Represents the model's confidence in each of the 10 classes for a given input\n",
    "dummy_outputs = torch.rand(4, 10)\n",
    "# Represents the correct class among the 10 being tested\n",
    "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
    "\n",
    "print(dummy_outputs)\n",
    "print(dummy_labels)\n",
    "\n",
    "loss = loss_fn(dummy_outputs, dummy_labels)\n",
    "print('Total loss for this batch: {}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we’ll be using simple stochastic gradient descent with momentum.\n",
    "\n",
    "It can be instructive to try some variations on this optimization scheme:\n",
    "\n",
    "Learning rate determines the size of the steps the optimizer takes. What does a different learning rate do to the your training results, in terms of accuracy and convergence time?\n",
    "\n",
    "Momentum nudges the optimizer in the direction of strongest gradient over multiple steps. What does changing this value do to your results?\n",
    "\n",
    "Try some different optimization algorithms, such as averaged SGD, Adagrad, or Adam. How do your results differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we have a function that performs one training epoch. It enumerates data from the DataLoader, and on each pass of the loop does the following:\n",
    "\n",
    "Gets a batch of training data from the DataLoader\n",
    "\n",
    "Zeros the optimizer’s gradients\n",
    "\n",
    "Performs an inference - that is, gets predictions from the model for an input batch\n",
    "\n",
    "Calculates the loss for that set of predictions vs. the labels on the dataset\n",
    "\n",
    "Calculates the backward gradients over the learning weights\n",
    "\n",
    "Tells the optimizer to perform one learning step - that is, adjust the model’s learning weights based on the observed gradients for this batch, according to the optimization algorithm we chose\n",
    "\n",
    "It reports on the loss for every 1000 batches.\n",
    "\n",
    "Finally, it reports the average per-batch loss for the last 1000 batches, for comparison with a validation run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-Epoch Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of things we’ll want to do once per epoch:\n",
    "\n",
    "Perform validation by checking our relative loss on a set of data that was not used for training, and report this\n",
    "\n",
    "Save a copy of the model\n",
    "\n",
    "Here, we’ll do our reporting in TensorBoard. This will require going to the command line to start TensorBoard, and opening it in another browser tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1000 loss: 2.1717964600920676\n",
      "  batch 2000 loss: 0.9321752298176289\n",
      "  batch 3000 loss: 0.7051929750447161\n",
      "  batch 4000 loss: 0.6380287983976305\n",
      "  batch 5000 loss: 0.5825936196520924\n",
      "  batch 6000 loss: 0.5695326576875522\n",
      "  batch 7000 loss: 0.522997462703148\n",
      "  batch 8000 loss: 0.5104436654730234\n",
      "  batch 9000 loss: 0.49308474537244185\n",
      "  batch 10000 loss: 0.4952390701759141\n",
      "  batch 11000 loss: 0.4624113521499312\n",
      "  batch 12000 loss: 0.4444122429790441\n",
      "  batch 13000 loss: 0.4385216388797271\n",
      "  batch 14000 loss: 0.4278125356932869\n",
      "  batch 15000 loss: 0.39571767111937517\n",
      "LOSS train 0.39571767111937517 valid 0.4296651780605316\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 0.3822799964947626\n",
      "  batch 2000 loss: 0.3802146837072214\n",
      "  batch 3000 loss: 0.4082624550810433\n",
      "  batch 4000 loss: 0.3747677474583252\n",
      "  batch 5000 loss: 0.37915061244531534\n",
      "  batch 6000 loss: 0.37926533519421357\n",
      "  batch 7000 loss: 0.38140475272962066\n",
      "  batch 8000 loss: 0.38034670303331225\n",
      "  batch 9000 loss: 0.35105618538991257\n",
      "  batch 10000 loss: 0.3536376900322357\n",
      "  batch 11000 loss: 0.3842199795834313\n",
      "  batch 12000 loss: 0.3584070911887684\n",
      "  batch 13000 loss: 0.3468198613179702\n",
      "  batch 14000 loss: 0.3423277017622022\n",
      "  batch 15000 loss: 0.33989165431653967\n",
      "LOSS train 0.33989165431653967 valid 0.3730338513851166\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 0.3240579486264687\n",
      "  batch 2000 loss: 0.29625674850774886\n",
      "  batch 3000 loss: 0.33788437662295656\n",
      "  batch 4000 loss: 0.3410449398945784\n",
      "  batch 5000 loss: 0.31483021319775434\n",
      "  batch 6000 loss: 0.3189915870522091\n",
      "  batch 7000 loss: 0.3254711688522802\n",
      "  batch 8000 loss: 0.3195269274674065\n",
      "  batch 9000 loss: 0.3494923338386288\n",
      "  batch 10000 loss: 0.2977668858261859\n",
      "  batch 11000 loss: 0.3330979030437884\n",
      "  batch 12000 loss: 0.3276756107229885\n",
      "  batch 13000 loss: 0.33154238461425123\n",
      "  batch 14000 loss: 0.3216811506494705\n",
      "  batch 15000 loss: 0.3072162611018539\n",
      "LOSS train 0.3072162611018539 valid 0.343028724193573\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 0.2974540507921483\n",
      "  batch 2000 loss: 0.30270247245451176\n",
      "  batch 3000 loss: 0.29229248701384314\n",
      "  batch 4000 loss: 0.3090817196467542\n",
      "  batch 5000 loss: 0.30420187833183443\n",
      "  batch 6000 loss: 0.30347143759990286\n",
      "  batch 7000 loss: 0.2775786739559262\n",
      "  batch 8000 loss: 0.30045182189167463\n",
      "  batch 9000 loss: 0.2772500331264127\n",
      "  batch 10000 loss: 0.31653565505229925\n",
      "  batch 11000 loss: 0.28738344668938587\n",
      "  batch 12000 loss: 0.28711608100853847\n",
      "  batch 13000 loss: 0.3011898504185319\n",
      "  batch 14000 loss: 0.2755644448480648\n",
      "  batch 15000 loss: 0.2801266105116374\n",
      "LOSS train 0.2801266105116374 valid 0.34984081983566284\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 0.2795910517865559\n",
      "  batch 2000 loss: 0.2605563573783612\n",
      "  batch 3000 loss: 0.288174892666951\n",
      "  batch 4000 loss: 0.26336117389161884\n",
      "  batch 5000 loss: 0.25973076217775815\n",
      "  batch 6000 loss: 0.2783609585749073\n",
      "  batch 7000 loss: 0.2695847715082709\n",
      "  batch 8000 loss: 0.275955986120307\n",
      "  batch 9000 loss: 0.27468236799282386\n",
      "  batch 10000 loss: 0.27597380809986133\n",
      "  batch 11000 loss: 0.2713258398458108\n",
      "  batch 12000 loss: 0.28215809422526944\n",
      "  batch 13000 loss: 0.2824828548624937\n",
      "  batch 14000 loss: 0.27731230519036765\n",
      "  batch 15000 loss: 0.2924090956987202\n",
      "LOSS train 0.2924090956987202 valid 0.31975841522216797\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load a saved version of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m GarmentClassifier()\n\u001b[0;32m----> 2\u001b[0m saved_model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(PATH))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PATH' is not defined"
     ]
    }
   ],
   "source": [
    "saved_model = GarmentClassifier()\n",
    "saved_model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you’ve loaded the model, it’s ready for whatever you need it for - more training, inference, or analysis.\n",
    "\n",
    "Note that if your model has constructor parameters that affect model structure, you’ll need to provide them and configure the model identically to the state in which it was saved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Understanding with Captum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
